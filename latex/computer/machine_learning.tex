% !Mode:: "TeX:UTF-8"
\documentclass{article}
\input{../public/package}
\input{../public/article}
\begin{document}
\title{Machine Learning}
\author{}
\maketitle
%% \newpage
\tableofcontents
\newpage
\section{Introduction}
algorithms for inferring unkowns from knows.

\textbf{Applications}
\begin{itemize}
\item Spam mail
\item Handwriting
\item Google Streetview
\item Speech Recognition
\item Netflix, 视频推荐
\item Navigation of robot
\item Climate modelling
\end{itemize}

\textbf{Classes of ML problems}:
\begin{itemize}
\item Supervised: Given $((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n))$
	\begin{itemize}
	\item classification
	\item regression
	\end{itemize}
\item unsupervised: Given $(\vector{x})$, find patterns in the data
	\begin{itemize}
	\item Clustering
	\item density estimation: Given data comes from a unkown probability distribution
	\item dimensional reduction: 降维(but perserve the structure)
	\end{itemize}
\item Semi-supervised: Given $((x_1, y_1), (x_2, y_2), \ldots, (x_k, y_k), x_{k+1}, \ldots, x_n)$, predict $y_{k+1}, \ldots, y_n$
\item Active learning
\item Decision theory
\item Reinforcement learning: rewards/losses, maximize lifetime reward
\end{itemize}
\href{http://i.imgbox.com/sVuBzaqV.png}{unsupervised ML}

\textbf{Generative Discriminative(区别对待) approaches}\\
Given $((x_1, y_1), (x_2, y_2), \ldots, (x_k, y_k), x_{k+1}, \ldots, x_n)$\\
discriminative: $P(y|x)$\\
geneerative: $P(x,y) = f(x|y)P(y) = P(y|x)f(x)$
It is called generative, because it use the density distribution $f(x)$ or $f(y)$

Examples of generative models include:
\begin{itemize}
\item Gaussian mixture model and other types of mixture model
\item Hidden Markov model
\item Probabilistic context-free grammar
\item Naive Bayes
\item Averaged one-dependence estimators
\item Latent Dirichlet allocation
\item Restricted Boltzmann machine
\end{itemize}

Examples of discriminative models used in machine learning include:
\begin{itemize}
\item Logistic regression, a type of generalized linear regression used for predicting binary or categorical outputs (also known as maximum entropy classifiers)
\item Linear discriminant analysis
\item Support vector machines
\item Boosting (meta-algorithm)
\item Conditional random fields
\item Linear regression
\item Neural networks
\end{itemize}

\section{K-Nearest Neighbor(KNN)}
Given $((x_1, y_1), (x_2, y_2), \ldots, (x_k, y_k), x_{k+1}, \ldots, x_n), x$\\
$x_i \in R^d, y_i \in \{0, 1\}$

\textbf{Majority vote of $k$ nearest points}\\
\href{http://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png}{KNN demo}

$k=1$, 找到最近的1个点\\
$d(x_i, x_j) = \norm{x_i - x_j}$

$k=3$, 找到最近的3个点, 看label 1多还是label 0多.

Prob interpretation. Fix $k$\\
$P(y) =$ fraction of points $x_i$ in $N_k(x)$ s.t $y_i = y$\\
有时也记为$P(y|x, D)$, this is discriminative

How to select parameter $k$?\\
Cross validation, etc.

\section{Tree: CART approach}
\subsection{Decision Trees(CART Approach)}
Given $((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)), x$\\

\textbf{Binary tree, minimize error in each leaf}.

see note in paper

\subsection{Regression Tree}
see note in paper

\subsubsection{Growing a regression tree}
Greedy algo

$x_i \in R^d$

1. First split: choose $j$ and $s$ to minimize the quantity:
$$
\min_y (\sum_{i: x_{ij} > s} (y - y_i)^2 + \sum_{i: x_{ij} \leq s} (y - y_i)^2)
$$
As the given data is finite, for a choosen $j$, there is only a finite possibilities for $s$, \\
so we can split the whole region into two regions, we note one of them as $R$.

2. Spliting region $R$: choose $j$ and $s$ to minimize
$$
\min_y (\sum_{i: x_{ij} > s \et x_i \in R} (y - y_i)^2 + \sum_{i: x_{ij} \leq s \et x_i \in R} (y - y_i)^2)
$$

3. Stop when one point

4. only consider splits resulting in regions with $\geq 5$ points in per region

\subsection{classification tree}
\subsubsection{Growing a classification tree}
see note in paper

\subsection{Generalization}
Impurity(不纯, 杂质) measures:
\begin{itemize}
\item misclassfication rate
\item entropy $H_R$
\item $F_R$: Gini index, $G_R = \sum_{y \in Y} P_R(y)(1 - P_R(y))$
\end{itemize}

Other issues about this kind of model
\begin{itemize}
\item Categorical predictiors
\item Loss matrix
\item Missing values, $(x_1, y_1), \ldots, (x_i, y_i)$, and for some $i,j$, $x_{ij}$ is missing, it is noted N/A
\item Linear combinations
\item Instability, means sensitive to the data, that is high variance, but we can use aggregation to deal with it.
\end{itemize}

\section{Bootstrap aggregating(Bagging)}
Ofen prove the performance

\noindent
Given $(x_1, y_1), (x_2, y_2), \ldots (x_n, y_n) \obey P \ iid(Independent Identically Distributed)$\\
Given $x$, predict $y$

我们知道, 如果我们有很多组的given data, 那么, 我们可以在每组数据中, 求得$x$对应的$y$, 然后对这些求得的$y$ 取平均值, 我们有理由确信, 如果given data的组数
足够多, 计算得到的平均值是很接近与真实值的.\\
bootstrap 就是类似于这样操作的一种方法.\\
由于我们知道数据的分布规律, 那么我们可以sampling 多次, 得到多组数据, 如下:\\
$(x_1^{(1)}, y_1^{(1)}), (x_2^{(1)}, y_2^{(1)}), \ldots (x_n^{(1)}, y_n^{(1)})$ \\
$(x_1^{(2)}, y_1^{(2)}), (x_2^{(2)}, y_2^{(2)}), \ldots (x_n^{(2)}, y_n^{(2)})$ \\
$\vdots$\\
$(x_m^{(m)}, y_m^{(m)}), (x_2^{(m)}, y_2^{(m)}), \ldots (x_n^{(m)}, y_n^{(m)})$ \\

\smallskip
True value is $y = f(x)$, $y^{(i)}$ is the estimater, $EY$ is the mean of $y^{(i)}$, and if $EY = y$, then $EY$ is an unbiased estimation.

the squared distance from the true value $y$:
$$E[(Y - y)^2] = E[(Y - EY)^2] = \sigma^2(Y)$$

Aggregation comes in:
define $Z =\dfrac{1}{m} \sum_{i = 1}^m Y^{(i)}$, then $EZ = y$.
And the expected loss:
$$
E[(Z - y)^2] = E[(Z - EZ)^2]
= \sigma^2(Z)
= \sigma^2(\dfrac{1}{m} \sum Y^{(i)})
= \frac{1}{m^2} \sigma^2(\sum Y^{(i)})
= \frac{1}{m^2} \sum \sigma^2(Y^{(i)})
= \frac{1}{m} \sigma^2(Y)
$$
意味着如果取$m \to \infty$, expected loss 将 $\to 0$

用the empirical distribution $\hat{P}$近似$P$, 然后从$\hat{P}$中resampling

\subsection{Bagging for classification}
\begin{itemize}
\item classification: majority vote, $C_1, C_2, \ldots, C_m$
\item regression: estimate probabilities, $P^{(1)}, \ldots, P^{(m)}$, PMF on $y$
\end{itemize}

\subsection{Random forests}
Given data set $D = (x_1, y_1), (x_2, y_2), \ldots (x_n, y_n)$

\begin{verbatim}
for i = 1, ..., B:
    choose bootstrap sample D_i from D
    construct tree T_i using D_i, s.t.
        at each node, choose random subset of features and only consider splitting on those features
\end{verbatim}

Usage:
Give $x$, take majority vote for classification, or average estimate probability for regression.

\section{Maximum Likelihood Estimation(MLE)}
最大似然估计提供了一种给定观察数据来评估模型参数的方法,即:"模型已定,参数未知".
简单而言,假设我们要统计全国人口的身高,首先假设这个身高服从服从正态分布,但是该分布的均值与方差未知.我们没有人力与物力去统计全国每个人的身高,
但是可以通过采样,获取部分人的身高,然后通过最大似然估计来获取上述假设中的正态分布的均值与方差.

最大似然估计中采样需满足一个很重要的假设,就是所有的采样都是独立同分布的

Given data set $D = (\vector{x}$ with $x_i \in R^d$\\
Assume a set of distributions $\{ P_\theta: \theta \in \Theta \}$ on $R^d$.\\
Assume $D$ is a sample from random variables $\vector{X} \obey P_\theta$ iid for some $\theta \in \Theta$

Goal: Estimate the true $\theta$ that $D$ comes from.
\begin{definition}
$\theta_{mle}$ is a MLE for $\theta$ if $\theta_{MLE} = \arg_{\theta \in \Theta} \max P(D|\theta)$ \\
where $P(D|\theta) = P(\vector{x} | \theta) = \prod_{i = 1}^n P(x_i|\theta) = \prod_{i=1}^n P(X_i = x_i|\theta)$,
and $L(\theta) = P(D|\theta)$ is the likelihood function
\end{definition}

Pros:
\begin{itemize}
\item easy
\item interpretable
\item Invariant under reparametrization: $g(\theta_{MLE})$ is a MLE for $g(\theta)$
\item Asymptotic properties
\item Consistent(当$n \to infty$, 有很大的概率使得$\theta$取到真值)
\item Normal
\item Efficient
\end{itemize}

Cons:
\begin{itemize}
\item point estimation: not representative of uncertanity\\
(如果对于未知参数的估计,给出一个确定的值叫做点估计.给出一个区间范围就上置信度,叫做区间估计.)
\item Overfitting: regression example
\item Wrong objective?(may maximize the wrong objective function)
\item Existence or uniqueness not guaranteed
\end{itemize}

\subsection{MLE for univariante Gaussian}
$X \obey N(\theta, \sigma^2)$ with $\theta \in \R$
$$P(x|\theta) = \dfrac{1}{\sqrt{2\pi \sigma^2}} \exp(-\dfrac{1}{2\sigma^2}(x-\theta)^2)$$
$D = (\vector{x}),\ X_i \obey N(\theta, \sigma^2),\ iid$
$$
P(D|\theta)
= P(\vector{x}| \theta)
= \prod_{i=1}^n P(x_i|\theta)
= (\dfrac{1}{\sqrt{2\pi \sigma^2}})^n \exp(-\dfrac{1}{2\sigma^2} \sum_{i=1}^n (x_i -\theta)^2)
$$
为了方便求导, 我们取对数
$$
\log(P(D|\theta)) = -\dfrac{n}{2} \log(2 \pi \sigma^2) - \dfrac{1}{2\sigma^2} \sum_{i=1}^n (x_i - \theta)^2
$$
对$\theta$求导, 然后令导数为$0$
$$
0 = \dfrac{\partial }{\partial \theta} \log(P(D|\theta))
= \dfrac{1}{\sigma^2} \sum_{i=1}^n (x_i - \theta)
= \dfrac{1}{\sigma^2} (\sum_{i=1}^n x_i - n \theta)
\Rightarrow \theta = \dfrac{1}{n} \sum_{i=1}^n x_i
$$
求二阶导我们可以验证这确实是一个maximum.

$$\theta_{MLE} = \mean{x} = \dfrac{1}{n} \sum_{i=1}^n x_i$$
这意味着, sample 的期望的最好估计就是sample的mean.

\subsection{MLE for a PMF on a finite  set}
$X \obey P,\ X \in \{1,2,\ldots, m\}$\\
例如掷骰子, $m=6$\\
$D = (\vector{x}),\ \vector{X} \obey P,\ iid$\\
$\sum_{i=1}^m P_\theta(i) = 1$\\
$P(X=i|\theta) = P(i|\theta) = P_\theta(i) = \theta_i$ with $\theta = (\theta_1, \ldots, \theta_m)$\\
骰子取$i$的概率为$\theta_i$

$$P(x|\theta) = \theta_x= \prod_{j= 1}^m \theta_j^{I(x=j)}$$
where $I(x=j)$ is a indicator.

$$\theta_{MLE} = \arg_{\theta_i: \sum_{i=1}^m \theta_i =1} \max P(D|\theta)$$
$$
\begin{aligned}
P(D|\theta)
& = P(\vector{x}| \theta) \\
& = \prod_{i=1}^n P(x_i|\theta) \\
& = \prod_{i=1}^n \theta_{x_i}\\
& = \prod_{i=1}^n \prod_{j=1}^m \theta_j^{I(x_i = j)}\\
& = \prod_{j=1}^m \prod_{i=1}^n \theta_j^{I(x_i = j)}\\
& = \prod_{j=1}^m \theta_j^{ \sum_{i=1}^n I(x_i = j)}\\
& = \prod_{j=1}^m \theta_j^{n_j}\\
\end{aligned}
$$
where $n_j = \#\{i: x_i = j\}$

取对数
$$ \log(P(D|\theta)) = \sum_{j=1}^m n_j \log(\theta_j) $$
$$ \dfrac{1}{n} \log(P(D|\theta)) = \sum_{j=1}^m \dfrac{n_j}{n} \log(\theta_j) $$
令$q_j = \dfrac{n_j}{n} $\\
由于从data set $D$中, 我们可以count 数字$j$出现的次数, 也就是说$n_j$是已知的,且我们容易发现$\sum_{j=1}^m q_j = 1$

$q$和$\theta$的relative entropy为
$$D(q||\theta) = \sum_{j=1}^m q_j \log(\dfrac{q_j}{\theta_j})$$
And we have $D(q||\theta) \geq 0$ 恒成立.

$$
\dfrac{1}{n} \log(P(D|\theta))
= \sum_{j=1}^m q_j \log(\theta_j)
= \sum_{j=1}^m q_j \log(\dfrac{\theta_j}{q_j}) + \sum_{j=1}^m q_j \log(q_j)
= -D(q||\theta) - H(q)
$$

$$
\theta_{MLE}
= \arg_{\theta_i: \sum_{i=1}^m \theta_i =1} \max P(D|\theta)
= \arg \max \dfrac{1}{n} \log(P(D|\theta))
= \arg \max D(q||\theta)
= q
$$
And it means:
$$\theta_{MLE} = q = (\dfrac{n_i}{n}, \dfrac{n_2}{n}, \ldots, \dfrac{n_m}{n})$$
\textbf{Empirical distribution}\\
同时, 这也是一个很自然的结果, 例如在掷骰子的时候, 为了估计骰子取到每个值的概率, 我们会将骰子掷很多次, 然后统计每个值出现的次数, 除以总的投掷次数, 就是每个值取到的概率.

\section{Exponential Families}
\begin{definition}
An exponential families is a set $\{ P_\theta: \theta \in \Theta \}$ of PMFs or PDFs on $R^d$, s.t.
$$P_\theta(x) = \exp(- \sum_{i=1}^m \eta_i(\theta) s_i(x)) h(x)/z(\theta)$$
where
$\Theta \subset R^k,\ x \in R^d,\ \eta_i: \Theta \rightarrow R,\ s_i:R^d \rightarrow R,\ h: R^d \rightarrow [0, \infty),\ z: \Theta \rightarrow [0, \infty)$
\end{definition}
$s_i$ are sufficient statistics, $h$ is support, scaling, $z$ is partition function.

我们也可以采用矩阵的写法:
$$P_\theta(x) = \exp(- \eta(\theta)^T s(x)) h(x)/z(\theta)$$

\begin{example}
指数分布:$P_\theta(x) = \theta \exp(-\theta x) I(x \geq 0)$\\
$\eta(\theta) = \theta,\ s(x) = x,\ h(x) = I(x \geq 0),\ z(\theta) = 1/\theta,\ \Theta = (0, \infty),\ k=d=1$
\end{example}

\begin{example}
$Bernoulli(\theta)$,
$$
\begin{aligned}
P_\theta 
& = \left\{
  \begin{array}{ll}
	\theta & \si x = 1 \\
	1 - \theta & \si x=0
  \end{array}
\right. \\
& = \theta^{I(x = 1)} (1 - \theta)^{I(x = 0)} h(x) \\
& = h(x) \exp \log (\theta^{I(x = 1)} (1 - \theta)^{I(x = 0)})\\
& = h(x) \exp (I(x=1) \log \theta + I(x=0) \log (1 - \theta))
\end{aligned}
$$

$\eta_1(\theta) = \log \theta,\ n_2(\theta) = \log (1 - \theta),\ s_1(x) = I(x=1),\ s_2(x) = I(x=0)$\\
$h(x) = I(x \in \{0,1\}),\ z(\theta) = 1$

另外, 对于同一个分布, 可以有不同的写法, 例如我们可以把上面的例子写成下面的形式:
$$
\begin{aligned}
P_\theta 
& = \theta^{I(x = 1)} (1 - \theta)^{I(x = 0)} h(x) \\
& = \theta^{I(x = 1)} (1 - \theta)^{1 - I(x = 1)} h(x)\\
& = (1 - \theta)(\dfrac{\theta}{1-\theta}^{I(x=1)}) h(x) \\
& = h(x) (1 - \theta) \exp(I(x=1) \log(\dfrac{\theta}{1-\theta}))
\end{aligned}
$$
\end{example}

\begin{example}
(not an exp family): Uniform $(0, \theta)$
\end{example}

常见的exp fam:\\
Exponential PDF: exponential, normal, Beta, Gamma, Chi-square\\
Exponential PMF: Bernoulli, Bonomial, Poisson, Geometric, Multinomial

exponential families具有的性质:
\begin{itemize}
\item Conjugate priors
\item Maximum entropy
\end{itemize}

\subsection{MLE for an exp fam}
$x \in R^d,\ \theta \in \Theta=R^k,\ \eta(\theta) = \theta$
$$P_\theta(x) = \exp(\theta^T s(x)) h(x)/z(\theta)$$

$D= (\vector{x}),\ x_i \in R^d,\ \vector{X} \obey P_\theta,\ iid$\\
$\theta_{MLE} = \arg_{\theta \in \Theta} P(D|\theta)$

$$
\begin{aligned}
P(D|\theta)
& = \prod_{i=1}^n P(x_i|\theta) \\
& = \prod_{i=1}^n \exp(\theta^T s(x_i)) h(x)/z(\theta) \\
& = z(\theta)^{-n} \exp(\theta^T \sum_{i=1}^n s(x_i)) \prod_{i=1}^n h(x_i) \\
& = z(\theta)^{-n} \exp(\theta^T s(D)) \prod_{i=1}^n h(x_i) \\
\end{aligned}
$$

取对数, 然后对$\theta_j$求导, 令其为零.具体的推导过程参见
\href{https://www.youtube.com/watch?v=LcbwmT1OAKo&list=PLD0F06AA0D2E8FFBA&index=29}{youtube (ML 5.3) MLE for an exponential family}

\section{MAP(Max a posteriori)}
Setup:
\begin{itemize}
\item Given $D = (\vector{x}), x_i \in R^d$
\item Assume a joint dist $P(D, \theta)$, where $\theta$ is a r.v
\item Goal: choose a good value of $\theta$ for $D$
\item Choose $\theta_{MAP} = \arg_\theta \max P(\theta | D)$
\end{itemize}
在给定数据$D$的情况下, $\theta$得到最可能取值, 注意和MLE的区别.
$\theta_{MLE} = \arg_\theta \max P(D|\theta)$

Pros:
\begin{itemize}
\item Easy interpretable
\item Avoid overfitting(MLE的一个缺点) - Regularization/Shrinkage
\item Tends to look like MLE asymptotically($n \to \infty$)
\end{itemize}

Cons:
\begin{itemize}
\item Not invariant under reparametrization, that is to say: $g(\theta_{MLE})$ is a MLE for $g(\theta)$
\item Point estimation - no repr of uncertainity in $\theta$\\
	从图\href{http://i.imgbox.com/k292Tu6D.png}{MAP max}中, 我们可以看到, $P(\theta|D)$在$\theta$接近0的位置取到最大值, 但是$\theta$只有很小的概率处于0的附近, 所以在图中这种情况, 我们的最佳选择是右边的一个极值点.
\item Must assume priori on $\theta$
\end{itemize}

\subsection{MAP for mean of a univariant Gaussian}
$D = (\vector{x},\ x_i \in R^d)$\\
Suppose $\theta$ is a r.v. $\obey N(\mu, 1)$ and $\vector{X}$ is conditionaly indep given $\theta$, 
and $X_i \obey N(\theta, \sigma^2)$ with $\sigma$ know\\
i.e: $P(\vector{x}|\theta) = \prod_{i =1}^n P(x_i|\theta)$


$$
\begin{aligned}
\theta_{MAP} 
& = \arg_\theta \max P(\theta | D)\\ 
& = \arg_\theta \max \dfrac{P(D|\theta) P(\theta)}{P(D)}\\ 
& \text{由于$P(D)$ 不是$\theta$的函数, 所以在$\theta$变化时, $P(D)$是定值}\\ 
& = \arg_\theta \max P(D|\theta) P(\theta)\\ 
& = \arg_\theta \max (\log(P(D|\theta)) + \log P(\theta))\\ 
\end{aligned}
$$
对$\theta$求导数, 令之为零, 求得$\theta$, 然后它是最大值点.
$$
\begin{aligned}
0 
& = \dfrac{\partial}{\partial \theta} (\log(P(D|\theta)) + \log P(\theta))\\
& = \dfrac{1}{\sigma^2} (\sum x_i - n \theta) + (\mu - \theta)\\
& = (\dfrac{\sum x_i}{\sigma^2} + \mu) - (\dfrac{n}{\sigma^2} + 1)\theta\\
\end{aligned}
$$
推出
$$
\theta 
= \dfrac{\dfrac{\sum x_i}{\sigma^2} + \mu}{\dfrac{n}{\sigma^2} + 1}
= \dfrac{\sum x_i + \sigma^2 \mu}{n + \sigma^2}
= \dfrac{n \dfrac{1}{n} \sum x_i + \sigma^2 \mu}{n + \sigma^2}
$$

$$ \theta_{MAP} = \dfrac{n}{n + \sigma^2} \mean{x} + \dfrac{\sigma^2}{n + \sigma^2} \mu $$
convex combination of sample mean and priori mean, and note that: 
$$\si n \to \infty,\ \theta_{MAP} = \mean{x}$$

$$ \theta_{MLE} = \mean{x} $$

\subsection{Difference between MLE and MAP}
\href{http://blog.163.com/silence\_ellen/blog/static/1761042222014413112444364/}{参数估计--MLE,MAP和贝叶斯估计}

在数据量大的时候,MAP的p(h)小到可以忽略,即"data overwhelms the prior." 也就是说MAP和MLE殊途同归,完全相等.\\
在数据量小的时候,由于MAP有先验知识,它比MLE更合理.\\
即便是大数据的情况下,由于数据很稀疏,在某一个范围或一个维度内,数据量其实也不算大,这时候用MAP效果也比MLE好.

\begin{example}
\href{http://jimbozhang.blogspot.com/2008/12/difference-between-map-and-mle.html}{example of MLE and MAP}

Suppose there are three facts:
\begin{itemize}
\item If a student was lazy, he has a probility of 0.3 to pass his exam.
\item If a student works hard, he has a probility of 0.8 to pass exam.
\item 10 percents students work hard, and 90 percents students were lazy in Tom's school.
\end{itemize}
Now Tom has passed his exam, we want to know if Tom was lazy.

by MLE:
\begin{itemize}
\item P(pass|lazy) = 0.3
\item P(pass|hard) = 0.8
\item P(pass|lazy) < P(pass|hard)
\end{itemize}
So, Tom is a working-hard student.

by MAP:
\begin{itemize}
\item P(lazy|pass) = P(pass|lazy) * P(lazy) / P(pass) = 0.27/P(pass) 
\item P(hard|pass) = P(pass|hard) * P(hard) / P(pass) = 0.08/P(pass)
\item P(lazy|pass) > P(hard|pass)
\end{itemize}
So, Tom must be a lazy student.

In a short, \textbf{MLE pay attention to P(result|condition)}, while \textbf{MAP pay attention to P(condition|result)}.\\
同时, 在这个例子中, 我们可以看到 
MLE 方法没有使用题目中给出的第三个信息($10\%$ students work hard, and $90\%$ students were lazy in Tom's school), 
而MAP 方法是使用了这个信息的.\\
但是不理解为什么使用了这个信息, $90\%$的用功学习, 最后有一个同学通过了考试, 他是lazy的概率竟然还更加大.
\end{example}

\section{Bayesian inference}
\begin{itemize}
\item Assume a priori dist $P(\theta)$
\item Bayesian procedures - min expected loss(averaging over $\theta$)
\item Objective(non-informative prioris) v.s subjective(belief-based priori)
\end{itemize}

Pros:
\begin{itemize}
\item Directly answer questions, eg:$P(99 < \theta < 101)$
\item Avoid pathologies
\item Avoid overfitting because using priori
\item Model selection( Occam's Razor - "when you have two competing theories that make exactly the same predictions, the simpler one is the better.")
\item Admissible(there is no other procedure which is always better)
\end{itemize}

Cons:
\begin{itemize}
\item Must assume priori, especially in the subjective case
\item Exact computation can be intractable(通常需要approximation)
\end{itemize}

Usual Prioris:
\begin{itemize}
\item Non-informative priori
\item Improper priori
\item Conjugate priori
\end{itemize}

\subsection{Conjugate Priori}
\begin{definition}
In Bayesian probability theory, if the posterior distributions $P(\theta|D)$ are in the same family $\mathcal{F}$ as 
the prior probability distribution $P(\theta)$, the prior $P(\theta)$ and posterior $P(\theta|D)$ are then called conjugate distributions, 
and the prior $P(\theta)$ is called a conjugate prior for the likelihood $P(D|\theta)$. ----from wiki
\end{definition}

弄出这么一个东西的好处是: 如果先验概率和后验概率具有同样的形式, 那么在数学计算上会非常方便.

Ex:
\begin{itemize}
\item Beta is conjugate to Bernoulli
\item Gaussian is conjugate to Gaussian
\item Any exponential family has a conjugate priori
\item the gamma distribution is the conjugate prior to many likelihood distributions: the Poisson, exponential, normal (with known mean), Pareto, gamma with known shape $\sigma$, inverse gamma with known shape parameter, and Gompertz with known scale parameter.
\end{itemize}

在\href{http://en.wikipedia.org/wiki/Conjugate\_prior\_distribution#Table\_of\_conjugate\_distributions}{wiki}上, 有一个列表.

下面来源于
\href{http://cos.name/2013/01/lda-math-beta-dirichlet/}{LDA-math-认识Beta/Dirichlet分布}

$$\text{先验分布} + \text{数据的知识} = \text{后验分布}$$
$$ Beta(p|k,n-k+1) + Count(m_1,m_2) = Beta(p|k+m_1,n-k+1+m_2) $$

其中 $(m_1,m_2)$ 对应的是二项分布$B(m_1+m_2,p)$的计数.更一般的,对于非负实数$\alpha,\beta$ ,我们有如下关系
$$ Beta(p|\alpha,\beta) + Count(m_1,m_2) = Beta(p|\alpha+m_1,\beta+m_2) $$

这个式子实际上描述的就是  Beta-Binomial 共轭.

此处共轭的意思就是,数据符合二项分布的时候,参数的先验分布和后验分布都能保持Beta 分布的形式,
这种形式不变的好处是,我们能够在先验分布中赋予参数很明确的物理意义,这个物理意义可以延续到后验分布中进行解释,
同时从先验变换到后验过程中从数据中补充的知识也容易有物理解释.

而我们从以上过程可以看到,Beta 分布中的参数$\alpha,\beta$都可以理解为物理计数,这两个参数经常被称为伪计数(pseudo-count).
基于以上逻辑,我们也可以把$Beta(p|\alpha,\beta)$写成下式来理解
\begin{equation}
Beta(p|1,1) + Count(\alpha-1,\beta-1) = Beta(p|\alpha,\beta)
\end{equation}
其中 $Beta(p|1,1)$ 恰好就是均匀分布$Uniform(0,1)$.

对于 \lasteq 式,我们其实也可以纯粹从贝叶斯的角度来进行推导和理解. 
假设有一个不均匀的硬币抛出正面的概率为$p$,抛$m$次后出现正面和反面的次数分别是$m_1,m_2$,
那么按传统的频率学派观点,$p$的估计值应该为 $\estimate{p}=\dfrac{m_1}{m}$.
而从贝叶斯学派的观点来看,开始对硬币不均匀性一无所知,所以应该假设$p \obey Uniform(0,1)$, 于是有了二项分布的计数$(m_1,m_2)$之后,
按照贝叶斯公式如下计算$p$ 的后验分布

\begin{align*} 
P(p|m_1,m_2) & = \frac{P(p)\cdot P(m_1,m_2|p)}{P(m_1,m_2)} \\ 
& = \frac{1\cdot P(m_1,m_2|p)}{\int_0^1 P(m_1,m_2|t)dt} \\ 
& = \frac{\binom{m}{m_1}p^{m_1}(1-p)^{m_2}}{\int_0^1 \binom{m}{m_1}t^{m_1}(1-t)^{m_2}dt} \\ 
& = \frac{p^{m_1}(1-p)^{m_2}}{\int_0^1 t^{m_1}(1-t)^{m_2}dt} 
\end{align*}
计算得到的后验分布正好是$Beta(p|m_1+1,m_2+1)$

\bigskip
$$
Dir(\overrightarrow{p}|\overrightarrow{\alpha}) + MultCount(\overrightarrow{m}) 
= Dir(p|\overrightarrow{\alpha}+\overrightarrow{m}) 
$$
以上式子实际上描述的就是 Dirichlet-Multinomial 共轭

而我们从以上过程可以看到,Dirichlet 分布中的参数$\overrightarrow{alpha}$都可以理解为物理计数.
类似于 Beta 分布,我们也可以把 $Dir(\overrightarrow{p}|\overrightarrow{\alpha})$作如下分解
$$
Dir(\overrightarrow{p}|\overrightarrow{1}) + MultCount(\overrightarrow{m}-\overrightarrow{1}) 
= Dir(\overrightarrow{p}|\overrightarrow{\alpha})
$$

\subsection{Beta-Bernoulli model}
$D = (\vector{x})$

伯努利分布是一个离散型的随机分布,其中的随机变量只有两类取值,$\set{1,0}$.
二项分布即重复$n$次的伯努利试验,记为 $X \obey b(n,p)$\\
多次抛掷硬币的实验就是二项分布

$\vector{X} \obey Bernoulli(\theta)$\\
$\theta \obey Beta(a,b)$ where $a,b$ are called \textbf{hyper parameters}
(因为$X$的分布用$\theta$来表示, $\theta$的分布用$a,b$来表示, 所以$a,b$是间接参数).\\
$P(\theta) = \dfrac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)} \propto \theta^{a-1}(1-\theta)^{b-1}$

\noindent
$P(X = 1|\theta) = \theta = \theta^{I(X=1)}\ (1-\theta)^{I(X=0)}$\\
$P(X = 0|\theta) = 1 - \theta = \theta^{I(X=1)}\ (1-\theta)^{I(X=0)}$\\
So $P(X|\theta) = \theta^{I(X=1)}\ (1-\theta)^{I(X=0)}$


$$
\begin{aligned}
P(\theta | D) 
& \propto_{\theta} P(D|\theta)P(\theta)\\
& = P(\theta) \prod_{i=1}^n P(x_i|\theta)\\
& \propto \theta^{a-1}(1-\theta)^{b-1} \cdot \prod_{i=1}^n \theta^{I(X_i=1)}\ (1-\theta)^{I(X_i=0)}\\
& \propto \theta^{a-1}(1-\theta)^{b-1} \cdot \theta^{\sum I(X_i=1)} \cdot (1-\theta)^{\sum I(X_i=0)}\\
& = \theta^{a-1}(1-\theta)^{b-1} \cdot \theta^{n_1} \cdot (1-\theta)^{n_0}\\
& = \theta^{a + n_1 - 1} (1-\theta)^{b + n_0 -1}\\
& \propto Beta(\theta | a + n_1, b + n_0)\\
\end{aligned}
$$

$$\Rightarrow P(\theta | D) = Beta(\theta | a + n_1, b + n_0)$$
这里先验概率密度$P(\theta)$ 与后验概率密度 $P(\theta|D)$ 都是属于Beta 分布族. 而$X$的分布式Bernoulli 分布.\\
所以根据 conjugate priori 的定义, Bernoulli(同时 Binomial) 分布的conjugate priori 是Beeta 分布

$\theta \obey Beta(a,b)$, 所以这里 the family of priori distribution $\mathcal{F} = Beta(a,b)$, 
而$P(\theta | D) \propto Beta(\theta | a + n_1, b + n_0)$, 所以$\theta|D$ 所满足的distribution 在 $\mathcal{F}$中, 而$X$ 满足的distribution 是 Bernoulli,
所以 Beta is conjugate to Bernoulli.

查阅资料得到:\\
$$\si \theta \obey Beta(a,b), \then E\theta = \dfrac{a}{a+b},\ \sigma^2(\theta) = \dfrac{ab}{(a+b)^2(a+b+1)},\ mode = \dfrac{a-1}{a+b-2}$$
其中mode 表示使得PDF 极大值点.

所以这里:
$$E[\theta|D] = \dfrac{a + n_1}{a + b + n},\ \sigma^2(\theta|D) = \dfrac{(a + n_1)(b + n_0) }{(a + b + n)^2(a +b + n +1)},\ mode = \dfrac{a + n_1 -1}{a + b + n -2}$$
where $n = n_1 + n_0$\\
同时我们可以注意到$E[\theta|D]$也是一个convex combination:
$$E[\theta|D] = \dfrac{a + n_1}{a + b +n} = \dfrac{a+b}{a+b+n} \dfrac{a}{a+b} + \dfrac{n}{a+b+n} \dfrac{n_1}{n}$$

结合我们之前学过的MLE 和MAP, 我们知道
\begin{itemize}
\item $\theta_{MLE} = empirical probability = \dfrac{n_1}{n}$
\item $\theta_{MAP}$ 为让$P(\theta|D)$最大, 这里刚好就是mode, 也就是$\theta_{MAP} = \dfrac{a+n_1 - 1}{a+b+n-2}$
\end{itemize}

\textbf{Predictive distribution}:\\
$$
\begin{aligned}
P(X=1|D) 
& = \int P(X=1|D,\theta) P(\theta|D) \\
& = \int P(X=1|\theta) P(\theta|D) \\
& = \int \theta P(\theta|D) \\
& = E[\theta|D]\\
\end{aligned}
$$

\subsection{Dirichlet Distribution}
$\theta = (\vector{\theta})$, $\alpha = (\vector{\alpha}) \et \alpha_i > 0$
$\theta \obey Dir(\alpha) \Rightarrow$ 
The PDF
$$ f(\theta) = \frac{1}{\mathrm{B}(\alpha)} \prod_{i=1}^K \theta_i^{\alpha_i - 1} I(\theta \in S) $$
where
$$
\mathrm{B}(\boldsymbol\alpha) 
= \frac{\prod_{i=1}^n \Gamma(\alpha_i)}{\Gamma(\alpha_0)}
$$
and 
$\alpha_0 = \sum_{i=1}^n \alpha_i$, 
$S = \{x \in R^n: x_i \geq 0, \sum_{i=1}^n x_i = 1\}$ ($S$ is called probability simplex)

关于这个分布的基本数字特征都可以在
\href{http://en.wikipedia.org/wiki/Dirichlet\_distribution}{wiki}
找到.

\textbf{求$\theta$的expectation}

我们会用到$\Gamma$函数的性质: $\Gamma(x+1) = x \Gamma(x)$
$$
\begin{aligned}
E[\theta_1]
& = \int_S \theta_1 f(\theta) d\theta \\
& = \int_S \theta_1 \frac{\Gamma(\alpha_0)}{\prod_{i=1}^n \Gamma(\alpha_i)} \prod_{i=1}^n \theta_i^{\alpha_i - 1} d\theta \\
& = \int_S \frac{\Gamma(\alpha_0)}{\prod_{i=1}^n \Gamma(\alpha_i)} \theta_1^{\alpha_1} \prod_{i=2}^n \theta_i^{\alpha_i - 1} d\theta \\
\end{aligned}
$$

令$\beta_1 = \alpha_1 + 1,\et \beta_i =  \alpha_i \si i > 1$, 那么 \\
$\beta_0 = \sum_{i = 1}^n \beta_i = \sum_{i = 1}^n \alpha_i + 1 = \alpha_0 + 1$ \\
$\Gamma(\beta_1) = \Gamma(\alpha_1 + 1) = \alpha_1 \Gamma(\alpha_1)$, 
$\Gamma(\beta_0) = \Gamma(\alpha_0 + 1) = \alpha_0 \Gamma(\alpha_0)$

$$
\begin{aligned}
E[\theta_1]
& = \int_S \frac{\Gamma(\beta_0) / \alpha_0}{\Gamma(\beta_1) / \alpha_1 \prod_{i=2}^n \Gamma(\beta_i)} \theta_1^{\beta_1 - 1} \prod_{i=2}^n \theta_i^{\beta_i - 1} d\theta \\
& = \dfrac{\alpha_1}{\alpha_0} \int_S \frac{\Gamma(\beta_0)}{\prod_{i=1}^n \Gamma(\beta_i)} \prod_{i=1}^n \theta_i^{\beta_i - 1} d\theta \\
& = \dfrac{\alpha_1}{\alpha_0} f(\theta)_\beta d\theta \\
& = \dfrac{\alpha_1}{\alpha_0}
\end{aligned}
$$
最后一步是根据: 对任何distribution来说, PDF的积分为1.

用同样的方法, 我们可以求得其他$\theta_i$的expectation

\subsection{Dirichlet-Categorical model}
The Dirichlet distribution is the conjugate prior distribution of the categorical distribution
and multinomial distribution (the distribution over observed counts of each possible category in a set of categorically distributed observations).

A categorical distribution (also called a "generalized Bernoulli distribution" or, less precisely, a "discrete distribution") 
is a probability distribution that describes the result of a random event that can take on one of $K$ possible outcomes, 
with the probability of each outcome separately specified.

\subsection{Posterior distribution for univariate Gaussian}
这个例子类似于MAP的例子

\section{Naive Bayes}
Generative model
\subsection{Naive Bayes Classification}
Find out the probability of the previously unseen instance belonging to each class, then simply pick the most probable class

Naive Bayes Classification use the naive Bayes assumption

Not necessarily Bayesian

setup: Given $D = ((x^{(1)}, y_1), \ldots, (x^{(n)}, y_n)),\ x^{(i)} \in R^d,\ y_i \in \mathcal{Y}$ with $\mathcal{Y} = \set{1,2,\ldots, m}$

Assume a family of distributions $P_\theta$ s.t.
$$\forall x \in R^d, y \in \mathcal{Y},\ P_\theta(x,y) = P_\theta(x|y) P_\theta(y) = \prod_{i=1}^d P_\theta(x_i|y) P_\theta(y)$$

Let $(x^{(1)}, y_1), \ldots, (x^{(n)}, y_n) \obey P_\theta,\ iid$ for some $\theta$, that is to say\\
If $(x,y) \obey P_\theta$, then $X_1, \ldots, X_d$ are independent given $Y$

Goal: for new $x \in R^d$, predict it's $y$\\
algo: 
\begin{enumerate}
\item Estimate $\theta$ from given data $D$
\item Compute $\estimate{y} = \arg_{y \in \mathcal{Y}} \max P_{\estimate{\theta}}(y|x)$
\end{enumerate}

$$
\begin{aligned}
\estimate{y} 
& = \arg_{y \in \mathcal{Y}} \max P_{\estimate{\theta}}(y|x) \\
& = \arg_{y \in \mathcal{Y}} \max \dfrac{P_{\estimate{\theta}} (x,y)}{ P_{\estimate{\theta}}(x) } \\
& = \arg_{y \in \mathcal{Y}} \max \dfrac{P_{\estimate{\theta}} (x|y) P_{\estimate{\theta}}(y)}{ P_{\estimate{\theta}}(x) } \\
& = \arg_{y \in \mathcal{Y}} \max P_{\estimate{\theta}} (x|y) P_{\estimate{\theta}}(y) \\
& = \arg_{y \in \mathcal{Y}} \max \prod_{i=1}^d P_{\estimate{\theta}} (x_i|y) P_{\estimate{\theta}}(y) \\
\end{aligned}
$$

\textbf{How to chooose the $P_\theta$?}
\begin{itemize}
\item If $X_i \in \set{1,\ldots, N}$, then e.g. $P_\theta(x_i |y) = q(x_i, y)$, PMF
\item If $X_i \in \set{1, 2, \ldots}$, then e.g. Poisson or Geometric or whatever
\item If $X_i \in \R$, then e.g. Gaussian or Gamma or whatever
\end{itemize}
对于$X=(X_1, \ldots, X_d)$的$d$个维度, 不同的维度还可以采用不同的分布

\textbf{How to estimate $\theta$?}\\
MLE or MAP(auusming priori on $\theta$)\\
Another option: "Bayesian" Naive Bayes

\textbf{Why CI(conditional independent)}\\
$P_\theta(x|y) = \prod_{i=1}^d P_\theta(x_i|y)$\\
can estimate $\theta$ more accurately with less data.\\
\textbf{Wrong but simple can be better than correct but complicated.}

\bigskip
\textbf{Advantages/Disadvantages of Na\"ive Bayes}\\
Advantages:
\begin{itemize}
\item Fast to train (single scan). Fast to classify 
\item Not sensitive to irrelevant features(样本量足够大的情况下)
\item Handles real and discrete data
\item Handles streaming data well
\end{itemize}

Disadvantages:
\begin{itemize}
\item Assumes independence of features
\end{itemize}

\subsection{Bayesian Naive Bayes}
Bayesian classifiers use Bayes theorem, which says
$$P(c_j|d) = \dfrac{P(d|c_j) P(c_j)}{P(d)}$$

\begin{itemize}
\item $P(c_j|d) = $probability of instance $d$ being in class $c_j$
\item [] This is what we are trying to compute
\item $p(d | c_j) =$ probability of generating instance $d$ given class $c_j$,
\item [] We can imagine that being in class $c_j$, causes you to have feature $d$ with some probability 
\item $p(c_j) =$ probability of occurrence of class $c_j$, 
\item [] This is just how frequent the class $c_j$, is in our database
\item $p(d) =$ probability of instance $d$ occurring
\item [] This can actually be ignored, since it is the same for all classes
\end{itemize}

\section{Linear Regression}
It's not just lines and planes, there is more.

Linear regression is the "work horse" of statistics and (supervised) machine learning. 
When augmented with kernels or other forms of basis function expansion, it can model also non-linear relationships. 
And when the Gaussian output is replaced with a Bernoulli or multinoulli distribution, 
it can be used for classification, as we will see below. So it pays to study this model in detail.

setup: Given $D = ((x_1, y_1), \ldots, (x_n, y_n)),\ x_i \in R^d,\ y_i \in \R$\\
Goal: Choose $f: R^d \rightarrow R$ to predict the $y$ for a new $x$

Simple case: $f(x) = w^T x = \sum_{i=1}^d w_i x(i)$ with $w \in R^d$\\
General case: $f(x) = w^T \varphi(x) = \sum_{i=1}^n w_i \varphi_i(x)$ with $\varphi: R^d \rightarrow R^n$ and $w \in R^n$

They are linear regression, because it's linear for $w$, not necessarily in $x$.\\
$R^d$ is the original space, $R^n$ is the feature space, so linear regression is linear in the feature space.

$\varphi_i(x)$ is called basic functions.

\begin{example}
Polynomial\\
$f(x) = w_i + w_2 x(1) + w_3 x(2) + w_4 x(1)^2 + w_5 x(2)^2 + w_6 x(1)x(2)$\\
Here, $\varphi(x) = (1, x(1), x(2), x(1)^2, x(2)^2, x(1)x(2))$
\end{example}
Other usual basis
\begin{itemize}
\item Radial Basis Function
\item Fourrier Basis
\item Wavelets: useful in image processing
\end{itemize}

由于$y = w^T \varphi(x) = w^T z$, 然后我们可以令$z$称为新的$x$, 
所以为了方便, 之后我们都使用$y = w^T x$来直接表示general case.

Choose Discriminative approach, the conditional distribution $P(y|x)$ 
instead of generative approach, the joint distribution $P(y,x)$

Assume some family $P_\theta(y|x)$, Estimate $\theta$ using $D$.\\
Which family should we choose? To make our life easier and 考虑到$y$ 是实数, we choose the Gaussian.
$$P_\theta(y|x) = N(y| \mu(x), \sigma^2(x))$$ where $\theta = (\mu, \sigma^2)$ with $w \in R^d, \sigma^2 > 0$
\note{这里的分布应该是$y$的啊, 不理解为什么有$\mu(x), \sigma^2(x)$}

But how we choose $\mu$ and $\sigma^2$?
\begin{definition}
\textbf{Gaussian Linear Regression} modles the data $D$ by assuming 
$$P_\theta(y|x) = N(y| w^T x, \sigma^2)$$ where $\theta = (w, \sigma^2)$ with $w \in R^d, \sigma^2 > 0$

$y = w^T x + \epsilon$ where $\epsilon \obey N(0, \sigma^2)$
\end{definition}

How to choose $f$? (minimize the expected loss)\\
choose square loss, $L(y, \estimate{y}) = (y - \estimate{y})^2$

$$
\begin{aligned}
\arg_y \min E_\theta(L(Y,y)|X= x)
& = E_\theta(y|X=x) \\
& = E_\theta(w^T x + \epsilon | X=x) \\
& = w^T x + E_\theta(\epsilon | X=x) \\
& = w^T x + E_\theta(\epsilon) \\
& = w^T x
\end{aligned}
$$
\note{等式的第一步?}
So, for Gaussian linear regression, with squared loss, choose $f(x) = w^T x$

But, what is $w$? we do not know $\theta$. That's where estimation comes in, so we need estimate $\theta$
using MLE, MAP, etc.

\subsection{MLE for Gaussian Lin Reg}
$Y \obey N(w^T x, \sigma^2)$, assume $\sigma^2$ known, $\theta = w$\\
$D = ((x_1, y_1), \ldots, (x_n, y_n)),\ x_i \in R^d,\ y_i \in R$\\
$\vector{Y}$ indep, $Y_i \obey N(w^T x_i, \sigma^2)$

$$\theta_{MLE} = \arg_\theta \max P(D|\theta)$$

$$
\begin{aligned}
P(D|\theta)
& = P(\vector{y}|\vector{x},\theta) \\
& = \prod_{i=1}^n P(y_i|x_i,\theta) \\
& = \prod_{i=1}^n \dfrac{1}{\sqrt{2\pi \sigma^2}} \exp(- \dfrac{1}{2\sigma^2}(y_i - w^T x_i)^2) \\
& = (\dfrac{1}{\sqrt{2\pi \sigma^2}})^n \exp(- \dfrac{1}{2\sigma^2} \sum_{i=1}^n (y_i - w^T x_i)^2) \\
\end{aligned}
$$
$$
\begin{bmatrix}
y_1 - w^T x_1 \\
\vdots \\
y_n - w^T x_n \\
\end{bmatrix}
=
\begin{bmatrix}
y_1 \\
\vdots \\
y_n \\
\end{bmatrix}
-
\begin{bmatrix}
w^T x_1 \\
\vdots \\
w^T x_n \\
\end{bmatrix}
=
y -
\begin{bmatrix}
x_1^T \\
\vdots \\
x_n^T \\
\end{bmatrix}
w
= y - A w
$$

$$
A = 
\begin{bmatrix}
x_1^T \\
\vdots \\
x_n^T \\
\end{bmatrix}
$$
$A$ is called \textbf{design matrix}, $n \times d$.

$w \in R^n$
所以如果写成 $w^T (x_1, \ldots, x_n)$的形式, 
那么就过就是$1 \times n \cdot n \times n = 1 \times n$, 而$y$是 $n \times 1$
$$
\begin{aligned}
P(D|\theta) 
& = (\dfrac{1}{\sqrt{2\pi \sigma^2}})^n \exp(- \dfrac{1}{2\sigma^2} (y - Aw)^T (y - Aw)) \\
& = (\dfrac{1}{\sqrt{2\pi \sigma^2}})^n \exp(- \dfrac{1}{2\sigma^2} \ps{y - Aw}{y - Aw}) \\
\end{aligned}
$$

$$
\begin{aligned}
\theta_{MLE} 
& = \arg_\theta \max P(D|\theta) \\
& = \arg_w \max (\dfrac{1}{\sqrt{2\pi \sigma^2}})^n \exp(- \dfrac{1}{2\sigma^2} \ps{y - Aw}{y - Aw}) \\
& = \arg_w \min \ps{y - Aw}{y - Aw} \\
& = \arg_w \min \ps{Aw}{Aw} - 2\ps{y}{Aw} + \ps{y}{y} \\
& = \arg_w \min \dfrac{1}{2}\ps{2 A^T A w}{w} - \ps{2 A^T y}{w} \\
\end{aligned}
$$

而 $\dfrac{1}{2} \ps{Ax}{x} - \ps{b}{x}$ 在 $Ax = b$处取得最小值. 所以
$$ 2 A^T A w = 2 A^T y \Rightarrow w = (A^T A)^{-1} A^T y = A^{\dagger} y $$
$A^\dagger$ is called \textbf{Pseudo-Inverse} of a Matrix, 
see \href{https://inst.eecs.berkeley.edu/~ee127a/book/login/def\_pseudo\_inv.html}{dagger matrix}

Intuition: \\
The solution to the least-square problem $\min_x \norm{Ax - y}$, is $x = A^\dagger y$.\\
That is to say, minimize the distance of $y$ and $Ax$.

\section{Bayesian Linear Regression}
\begin{itemize}
\item Why not use MLE? overfitting
\item Why not use MAP? Not interval estimate
\item Why Bayesian? Optimize loss fn
\end{itemize}

\subsection{Posterior for linear regression}
Setup:$D = ((x_1, y_1), \ldots, (x_n,y_n)),\ x_i \in R^d, y_i \in R$\\
Model: $\vector{Y}$ indep given $w$, $Y_i \obey N(w^T x_i, a^{-1})$ with $a = \dfrac{1}{\sigma^2}$, and $a$ is called precision.\\
$w \obey N(0, b^{-1}I),\ b > 0$, $(w = (w_1, \ldots, w_d)^T)$\\
Assume $a, b$ are knowm. So $\theta = w$

Likelihood:
$$ P(D|w) \propto \exp(- \dfrac{a}{2} \ps{y - Aw}{y - Aw}) $$

Posteriori:
\begin{equation}
\begin{aligned}
P(w|D) 
& \propto P(D|w) P(w) \\
& \propto \exp(- \dfrac{a}{2} \ps{y - Aw}{y - Aw}) \cdot \exp(-\dfrac{1}{2} w^T (b^{-1}I)^{-1} w) \\
& \propto \exp(- \dfrac{a}{2} \ps{y - Aw}{y - Aw}) \cdot \exp(-\dfrac{b}{2} w^T w) \\
& \propto \exp(- \dfrac{a}{2} \ps{y - Aw}{y - Aw} -\dfrac{b}{2} w^T w) \\
\end{aligned}
\end{equation}

multivairant Gaussian distribution的形式
$$\propto \exp(-\dfrac{1}{2} (x - \mu)^T C^{-1} (x - \mu))$$
由于 \lasteq 中exp的里面是一个二次型, 与 multivariant Gaussian distribution的形式一致(具体的推导继续往下看), 所以
$P(w|D)$是一个 multivairant Gaussian distribution.

\begin{equation}
a \ps{y - Aw}{y - Aw} + b w^T w = a y^T y - 2aw^TA^Ty + w^T(aA^TA+bI)w
\end{equation}

由于covariance matrix 是对称且可逆, 所以 precision matrix也是对称且可逆
$$(x - \mu)^T \Lambda (x - \mu)) = x^T \Lambda x - 2 x^T \Lambda \mu + const$$
将这个形式与 \lasteq 对比($x$相当于$w$), 得到
$$ \Lambda = aA^TA + bI $$
我们容易验证$\Lambda$ 是对称且可逆的(用vecteur propre).
$$a w^T A^T y = w^T \Lambda \mu \Rightarrow \mu = a \Lambda^{-1} A^T y$$
所以
$$P(w|D) = N(w| \mu, \Lambda^{-1})$$

\bigskip
MAP estimation of $w$: 
$$w_{MAP} = a \Lambda^{-1} A^T y = a (aA^TA + bI)^{-1}A^Ty = (A^TA + \dfrac{b}{a}I)^{-1} A^T y$$

$\dfrac{b}{a}$ regularization parameter

再上一个section中, 我们求得
$$w_{MLE} = (A^T A)^{-1} A^T y = A^\dagger y$$

\subsection{Predictive distribution for linear regression}
Predictive: $P(y|x, D)$

Goal: $P(y|x,D) \propto \int N(w|...) g(y)dw \propto g(y) \propto N(y|...)$

$$
\begin{aligned}
P(y|x, D)
& = \int P(y|x,D,w) P(w|x,D) dw \\
& = \int P(y|x,w) P(w|D) dw \\
& = \int N(y|w^Tx, a^{-1}) \cdot N(w|\mu, \Lambda^{-1}) dw \\
& = \int \exp( - \dfrac{a}{2} (y - w^Tx)^2) \cdot \exp( - \dfrac{1}{2} (w-\mu)^T \Lambda (w - \mu)) dw \\
& \ldots \\
& \propto \exp(-\dfrac{\lambda}{2} (y-u)^2) \\
& = N(y|u, \dfrac{1}{\lambda})
\end{aligned}
$$

$$u = \mu^T x$$
$$\dfrac{1}{\lambda} = \dfrac{1}{a} + x^T \Lambda^{-1} x$$

在上一个subsection中, 我们求得
$$P(w|D) = N(w| \mu, \Lambda^{-1})$$
\section{K-means Cluestering}
无监督, greedy algo, a special case of EM algo

Given $D = (\vector{x}), x_i \in R^d$

Intuition: points are near to the center of their cluster

Assume $K$ clusters, with unknown centers $\mu_1, \mu_2, \ldots, \mu_k$
$$
L
= \sum_{j = 1}^k \sum_{i | x_i \in\ cluster\ j}\norm{x_i - \mu_j}^2
= \sum_{j = 1}^k \sum_i^n a_{ij}\norm{x_i - \mu_j}^2
$$
where
$$
a_{ij} =
\left\{
  \begin{array}{ll}
    1, & \si x_i \in\ cluster\ j\\
    0, & \sinon
  \end{array}
\right.
$$
We want to choose $a_{ij}$ and $\mu_i$ to minimize $L$.

K-means: try to minimize $L$ with repect to(wrt) $a$ and $\mu$
\begin{enumerate}
\item Init $\mu_1, \mu_2, \ldots, \mu_k$
\item Choose optimal $a$ for fixed $\mu$
\item Choose optimal $\mu$ for fixed $a$
\item Repeat 2 and 3 until convergence
\end{enumerate}

For step 2:\\
对于固定的$\mu$, 也就是说我们知道了所有clusters的centers, 需要将$x_i$分配到这些clusters中, 直觉告诉我们应该\\
assign $x_i$ to the nearset $\mu_j$. i.e.
$$
a_{ij} =
\left\{
  \begin{array}{ll}
  1, & \si j = \arg \min_l \norm{x_i - \mu_l}^2\\
    0, & \sinon
  \end{array}
\right.
$$

For step 3:\\
对于固定$a$, 也就是说我们知道了$x_i$都是属于哪个cluster的, 然后需要找出最佳的cluster's center.\\
首先我们的直觉告诉我们, cluster center应该为属于这个cluster的点的中心, 也就是平均值.

$$
\begin{aligned}
\end{aligned}
L
= \sum_{j = 1}^k \sum_i^n a_{ij}\norm{x_i - \mu_j}^2
= \sum_{j = 1}^k \sum_i^n a_{ij}(x_i - \mu_j)^T (x_i - \mu_j)
$$

$$
0 = \grad_{\mu_j}{L} = \sum_i \sum_l a_{ij} \grad{(x_i - \mu_l)^T (x_i - \mu_l)}
$$

例如: $n=3, k=2, d=2$, 也就是说把3个二维的数据分到两个clusters中.\\
$x_i = (x_{i1}, x_{i2})^T$
$\mu_i = (\mu_{i1}, \mu_{i2})^T$
$a_{ij}$ 表示第$i$个点属于第$j$个cluster.

$$
\begin{aligned}
L
= & \sum_{j = 1}^2 \sum_{i=1}^3 a_{ij}(x_i - \mu_j)^T (x_i - \mu_j) \\
= &  a_{11}(x_1 - \mu_1)^T (x_1 - \mu_1) + a_{12}(x_1 - \mu_2)^T (x_1 - \mu_2) \\
& + a_{21}(x_2 - \mu_1)^T (x_2 - \mu_1) + a_{22}(x_2 - \mu_2)^T (x_2 - \mu_2) \\
& + a_{31}(x_3 - \mu_1)^T (x_3 - \mu_1) + a_{32}(x_3 - \mu_2)^T (x_3 - \mu_2) \\
\end{aligned}
$$
如果我对$\mu_1$求gradient, 那么不含有$\mu_1$(这里就是含有$\mu_2$)的项就为0,
$$
\begin{aligned}
\grad_{\mu_1}{L}
& = \sum_{i = 1}^3 a_{i1}\grad{(x_i - \mu_1)^T (x_i - \mu_1)} \\
& = \sum_{i = 1}^3 a_{i1} \times (-2(x_i - \mu_1)) \\
& = \sum_{i = 1}^3  -2a_{i1}(x_i - \mu_1) \\
\end{aligned}
$$
上式用到了simulation et optimisation中学到的一个公式:
$$
F(x)= \frac{1}{2} \ps{Ax}{x} - \ps{b}{x}
$$
\`ou, A une matrice de dimension $n$, sym\'trique d\'efinie positive. 那么
$$DF(x).h = \ps{Ax - b}{h}$$
$$\grad{F(x)} = Ax - b$$
且$F(x)$ est une fontion convexe, 所有有一个minimum

所以
$$
\begin{aligned}
0 = \grad_{\mu_j}{L}
&= \sum_i \sum_l a_{il} \grad{(x_i - \mu_l)^T (x_i - \mu_l)} \\
&= \sum_i a_{ij} \grad{(x_i - \mu_j)^T (x_i - \mu_j)} \\
&= \sum_i -2a_{ij} (x_i - \mu_j) \\
&= -2(\sum_i a_{ij}x_i - \mu_j \sum_i a_{ij})
\end{aligned}
$$

$$
\Rightarrow
\mu_j = \dfrac{\sum_i a_{ij}x_i}{\sum_i a_{ij}}
$$
$\sum_i a_{ij}$  表示属于cluster $j$个点的个数\\
所以这确实是cluster的重心

为了确认L在这个$\mu_j$取到的是一个minimum, 而不是maximum, 我们求一下二阶导.

$$
\frac{\partial }{\partial \mu_{jk}} \grad_{\mu_{j} L}
= 2(\sum_i a_{ij}) e_k
\Rightarrow
\grad^2_{\mu_j} L = 2(\sum_i a_{ij})I > 0
$$
所以这是一个minimum, 而不是一个maximum

\href{https://www.youtube.com/watch?v=zHbxbb2ye3E}{K-means demo}

\section{EM(expectation-maximization) algo}
A class of algos,
it's more of an approach to derive an aglo for approximately obtaining (MLE)maximum-likelihood estimation or (MAP)maximum a posteriori estimates of parameters
when some of the data is missing.

Given: $x = (\vector(x))$\\
Model: $(X, Z) \obey p_\theta$ for some (unkown) $\theta \in \Theta$

Motivation of EM:

\end{document}
