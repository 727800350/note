% !Mode:: "TeX:UTF-8"
\documentclass{article}
\input{../public/package}
\input{../public/article}
\begin{document}
\title{Probablit\'e et Statistiques}
\maketitle
\tableofcontents
\newpage
Probability can be applied to any problem involving uncertainty.\\
In machine learning, uncertainty comes in many forms: what is the best prediction (or decision) given some data?
what is the best model given some data? what measurement should I perform next? etc.
\section{Mesure}
\subsection{$\sigma-algebra$}
une tribu ou $\sigma$-alg\`ebre (lire sigma-alg\`ebre) ou plus rarement corps de Borel1
sur un ensemble X est \textbf{un ensemble non vide de parties de X},
\textbf{stable}(closed en anglais) par passage au \textbf{compl\'ementaire} et par \textbf{union d\'enombrable}
(donc aussi par \textbf{intersection d\'enombrable} comme $\cap_{i=1}^{\infty} E_i = \cap(E_i^c)^c = (\cup E_i^c)^c \in A$).\\
Les tribus permettent de d\'efinir rigoureusement la notion d'\textbf{ensemble mesurable}.

\begin{definition}
Soit $X$ un ensemble. On appelle tribu (ou $\sigma-algebre$) sur $X$, un ensemble $\mathcal{A}$ de parties de $X$\ ($A \subset P(X)$) qui v\'erifie:
\begin{enumerate}
\item $\mathcal{A} \not=\varnothing$
\item $\forall A \in \mathcal{A}$ ,  ${}^c A \in\mathcal{A}$  (o\`u ${}^cA$ d\'esigne le compl\'ementaire de $A$ dans $X$).
\item si $\forall i \in \mathbb{N}$, $A_i \in\mathcal{A}$  alors  $\bigcup_{i\in\mathbb{N} } A_i \in\mathcal{A}$
		(l'union est dite d\'enombrable parce que l'ensemble des indices l'est).
\end{enumerate}
\end{definition}

\begin{example}
Un tribu discr\`ete :  $\mathcal A = \mathcal P(X)$  o\`u  $\mathcal P(X)$ repr\'esente l'ensemble de toutes les parties de $X$.

Si $X=\{a,b,c,d\}$ alors  $\mathcal A=\{\varnothing, \{a\}, \{b, c, d\}, X\}$ est une tribu sur $X$. C'est la plus petite tribu contenant l'ensemble  $\{a\}$.
\end{example}

\begin{definition}
Given $C \subset 2^{\Omega}$, the \textbf{$\sigma-algebra$ generated by $C$}, noted as $\sigma(C)$, is the \textbf{smallest} $\sigma-algebra$ containing $C$.(smallest means: $\sigma(C) = \cap_{\sigma-algebra A \supset C}\ A$)
\end{definition}

$\sigma(C)$ always exists, because:
\begin{enumerate}
\item $2^{\Omega}$ is a $\sigma-algebra$ $\Rightarrow \sigma(C)$ is not empty
\item Any intersections of $\sigma-algebra$ is a $\sigma-algebra$
\end{enumerate}
\begin{proof}
证明intersection:\\
$$
\begin{aligned}
& \forall x \in A_1 \cap A_2\\
& \Rightarrow x \in A_1  \et x \in A_2\\
& \Rightarrow x^c \in A_1 \et x^c \in A_2\\
& \Rightarrow x^c \in A_1 \cap A_2\\
\end{aligned}
$$

$$
\begin{aligned}
& \forall x_1, x_2 \in A_1 \cap A_2\\
& \Rightarrow x_1^c, x_2^c \in A_1 \cap A_2\\
& \Rightarrow x_1^c \cap x_2^c \in A_1 \cap A_2\\
& \Rightarrow (x_1 \cup x_2)^c \in A_1 \cap A_2\\
& \Rightarrow ((x_1 \cup x_2)^c)^c \in A_1 \cap A_2\\
& \Rightarrow (x_1 \cup x_2) \in A_1 \cap A_2\\
\end{aligned}
$$
\end{proof}

\begin{example}
均匀掷骰子, 如果我们只关注骰子1号面出现的时间, 即$C= \{\{1\}\}$, 那么
$$\sigma(C) = \{ \emptyset, \Omega, \{1\}, \{2,3,4,5,6\} \}$$
\end{example}

\begin{example}
当样本空间为实数区间时, Borel algebra是研究中常用的事件域, 一维的Borel algebra定义为:
\begin{definition}
包含R(实数集)上所有形如$(-\infty, a]$的最小$\sigma-algebra$, 记为$\mathcal{B} = \sigma((-\infty, a], \forall a \in R)$
\end{definition}
\end{example}

\subsection{Measure}
\begin{definition}
A measure $\mu$ on $\Omega$ with $\sigma-algebra A$ is a function $\mu: A \rightarrow [0, \infty]$, s.t.
\begin{enumerate}
\item $\mu(\emptyset) = 0$
\item \textbf{countable additivity}: $\mu(\cup_{i=1}^{\infty} E_i) = \sum_{i=1}^{\infty}\mu(E_i)$ for $\forall E_i \in A$ and pairewise disjoint.
\end{enumerate}
\end{definition}

Basic properties of a \textbf{measure space} $(\Omega, A, \mu)$:
\begin{enumerate}
\item $P(\emptyset) = 0$
\item $E,F \in A$ and $E \subset F$, then $\mu(E) \leq \mu(F)$
\item $P(\cup_{i=1}^{\infty} E_i) \leq \sum_{i=1}^{\infty}P(E_i)$ for $\forall E_i \in A$
\item $P(\cup_{i=1}^{\infty} E_i) = \sum_{i=1}^{\infty}P(E_i)$ for $\forall E_i \in A$ and pairewise disjoint.
\item \textbf{Continuity from below}\\
If $E_i \subset E_2 \subset,\ldots $, then $P(\cup_{i=1}^{\infty} E_i) = \lim_{i \to \infty} P(E_i)$
\item \textbf{Continuity from above}\\
If $E_i \supset E_2 \supset,\ldots $, then $P(\cap_{i=1}^{\infty} E_i) = \lim_{i \to \infty} P(E_i)$
\end{enumerate}

\begin{definition}
\textbf{lebesgue measure} on $R$($\Omega = R, A = B(R) = Borel algebra$),s.t
$$\mu(a,b) = b -a$$ for any $a,b \in R$ and $a < b$
\end{definition}
显然, lebesgue meaure is not a prob measure.

\begin{definition}
A \textbf{Borel measure} on $R$ is a measure on $(R, B(R))$
\end{definition}

\begin{definition}
\textbf{Kolmogorov's axioms: }
\textbf{A probability measure} is a measure $P$ s.t. $P(\Omega) = 1$
\end{definition}

\begin{definition}
A \textbf{CDF} is a fonction $F: R \rightarrow R$, such that:
\begin{enumerate}
\item $x \leq y \Rightarrow F(x) \leq F(y)$ with $x,y \in R$
\item 右连续的非降函数: $\lim_{x \to a^{+}}F(x) = F(a)$
\item $\lim_{x \to \infty}F(x) = 1$
\item $\lim_{x \to -\infty}F(x) = 0$
\item 概率计算公式: $P(x_1 < X \leq x_2) = F(x_2) - F(x_1),\ P(X=x) = F(x) - F(x^{-})$
\end{enumerate}
\end{definition}
从概率计算公式的后面一个可以看出为什么CDF是右连续的(对于跳跃性的CDF, 画出示意图看一目了然).

\begin{theorem}
$$F(x) \equiv P((-\infty, x])$$
defines an equivalence between CDFs $F$ and (Borel) probability measure $P$ on $R$.
\end{theorem}

\section{Prob}
\begin{theorem}
\textbf{Chain rule}\\
If $P(A_1 \cap A_2 \ldots A_{n-1}) > 0$
$$ P(A_1 \cap A_2 \ldots \cap A_n) = P(A_1) P(A_2 | A_2) P(A_3 | A_1 \cap A_2) \ldots P(A_n | A_1 \cap A_2 \ldots A_{n-1}) $$
\end{theorem}
Proof by induction

假设$\{A_i\}$是事件集合里的部份集合,对于任意的$A_i$,贝叶斯定理可用下式表示:
$$
P(A_i|B) = \frac{P(B | A_i)\, P(A_i)}{\sum_j P(B|A_j)\,P(A_j)} , \!
$$
通常称
\begin{itemize}
\item $P(A_i)$ 为\textbf{先验(A priori)概率}, 之所以称为"先验"是因为它不考虑任何B方面的因素
\item $P(B|A_i)$ 为\textbf{转移(transition)概率}
\item $P(A_i|B)$ 为\textbf{后验(A postriori)概率}
\end{itemize}
$A_i$是$m$个原因事件, $B$是某种结果事件, 贝叶斯公式正是基于结果$B$推测某种起因$A_i$的可能性的方法.

\begin{definition}
\textbf{Conditional measure} $Q(A) = P(A|B)$ defines a conditional prob measure $Q$ given $B$.
\end{definition}

\section{Random variable(r.v)}
\begin{definition}
Given a prob measure space $(\Omega, A, P)$, a r.v is a function $X: \Omega \rightarrow R$, s.t.
$$\{\omega \in \Omega: X(\omega) \leq x\} \in A, \forall x \in R$$
\end{definition}

Notation:\\
$$\{X \leq x\} = \{\omega \in \Omega: X(\omega) \leq x\}$$
$$P(X \leq x) = P(\{X \leq x\}) = P(\{\omega \in \Omega: X(\omega) \leq x\})$$

\begin{definition}
The CDF of a r.v $X$ is $F: R \rightarrow [0,1]$, s.t.
$$F(x) = P(X \leq x)$$
\end{definition}

\begin{definition}
The \textbf{distribution} of a r.v $X$ is prob measure $P_X$ on $R$ s.t.
$$P_X(B) = P(X^{-1}(B)) = P(X \in B), \forall A \in B(R)$$
\end{definition}
$R$ 是 r.v $X$所有可能的结果所在的空间, 而$B(R)$ 是可能的结果组成的所有可能的集合, 所以distribution 实际上就是r.v $X$的所有可能结果的概率.

\textbf{Types of r.v}
%% \begin{definition}
%% \end{definition}
\begin{definition}
A r.v is \textbf{discret} if $X(\Omega)( = \{X(\omega): \omega \in \Omega\})$ is countable(可以为无穷多个). (i.e $X(\Omega) = \{x_1, x_2,\ldots \}$)
\end{definition}

\begin{definition}
A r.v is has a \textbf{density} if $F(x) = \int_{-\infty}^x f(u)du, \forall x \in R$
\end{definition}

Let $Q = P_X$(distribution of $X$), let $J = \{x \in R: Q(x) > 0\}$
$$Q_d(A) = Q(A \cap J)$$
$$Q_c(A) = Q(A) - Q(A \cap J)$$
所以$Q = Q_d + Q_c$, d is for discret part(as CDF may have jumps), c for continu part

$$Q_c = Q_{ac} + Q_{sc}$$
as for absolutely continued, sc for singular continued

if $X$ discret, then $Q = Q_d$
if $X$ has a density, then $Q = Q_{ac}$

\warning{$Q = Q_c \nRightarrow X$ has a density}
反例, \href{http://en.wikipedia.org/wiki/Cantor\_function}{Cantor function}(一个连续,却不绝对连续的函数) 为 CDF.

概率质量函数(probability mass function,简写为pmf)是离散随机变量在各特定取值上的概率.

概率质量函数和概率密度函数(probability density function,简写为pdf)不同之处在于:
概率质量函数是对离散随机变量定义的,本身代表该值的概率;
概率密度函数是对连续随机变量定义的,本身不是概率,只有对连续随机变量的概率密度函数在某区间内进行积分后才是概率.

\subsection{Random vector}
\begin{definition}
Given a prob measure space $(\Omega, A, P)$, a random vector is a (mmeasure) $X: \Omega \rightarrow R^d$, with $d \in {1, 2, \ldots}$
\end{definition}

\begin{definition}
A random vector is discret if $X(\Omega)$ is countable.
\end{definition}

Now we fix $(X,Y) \in R^2$ with $P(x,y) = P(X=x, Y=y)$
\begin{definition}
The marginal PMF of X is $P_X(x) = P(X = x)$
\end{definition}
我们可以推出: $$P_X(x) = \sum_{y} P(x,y)$$

\subsection{Independent r.v.s}
\begin{definition}
$X$ and $Y$ are independent if $P_{X,Y}(x,y) = P_X(x)P_Y(y), \forall x, y$ where $P_X(x)$ is the marginal PDF, $X$ and $Y$ are discret.
\end{definition}

\begin{definition}
$X$ and $Y$ are independent if $f_{X,Y}(x,y) = f_X(x)f_Y(y), \forall x, y$ where $f_X(x)$ is the marginal PDF, $X$ and $Y$ have densities.
\end{definition}

\section{指数分布(Exponential distribution)}
\label{sec.distribution.exponential}
一种\textbf{连续概率分布}.指数分布可以用来表示独立随机事件发生的时间间隔,比如旅客进机场的时间间隔,中文维基百科新条目出现的时间间隔等等.

\textbf{概率密度函数}
一个指数分布的概率密度函数是
$$f(x;\lambda )=\left\{{\begin{matrix}\lambda e^{{-\lambda x}}&,\;x\geq 0,\\0&,\;x<0.\end{matrix}}\right.$$
其中$\lambda  > 0$是分布的一个参数,常被称为率参数(rate parameter).即每单位时间发生该事件的次数.
指数分布的区间是$[0,\infty)$. 如果一个随机变量X 呈指数分布,则可以写作:$X \sim Exponential(\lambda )$.
$$
\int_0^{\infty} f(x)dx = 1
$$
\href{http://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Exponential\_distribution\_pdf.png/800px-Exponential\_distribution\_pdf.png}{Exponential 概率密度函数}
	
\textbf{累积分布函数}\\
累积分布函数可以写成:
$$F(x;\lambda )=\left\{{\begin{matrix}1-e^{{-\lambda x}}&,\;x\geq 0,\\0&,\;x<0.\end{matrix}}\right.$$
\href{http://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Exponential\_distribution\_pdf.png/800px-Exponential\_distribution\_pdf.png}{Exponential 累积分布函数}
	
随机变量$X$ (概率参数是$\lambda$ ) 的期望值是:
$$
{\mathbf  {E}}[X]=\int_0^{\infty} xf(x)dx = {\frac  {1}{\lambda }}
$$
比方说:如果你平均每个小时接到2次电话,那么你预期等待每一次电话的时间是半个小时.
$X$ 的方差是:
$${\mathbf  {D}}[X]={\frac{1}{\lambda ^{2}}}
$$
$X$ 的偏离系数是: $V[X] = 1$

\textbf{与泊松过程的关系}\\
泊松过程是一种重要的随机过程.泊松过程中,第k次随机事件与第$k+1$次随机事件出现的时间间隔服从指数分布.这是因为,第$k$次随机事件之后长度为$t$的时间段内,第$k+1$次随机事件出现的概率等于$1$减去这个时间段内没有随机事件出现的概率.而根据泊松过程的定义,长度为$t$的时间段内没有随机事件出现的概率等于
$$
{\frac  {e^{{-\lambda t}}(\lambda t)^{0}}{0!}}=e^{{-\lambda t}}.
$$
所以第k次随机事件之后长度为t的时间段内,第$k+1$次随机事件出现的概率等于$1-e^{{-\lambda t}}$,这是指数分布.这还表明了泊松过程的无记忆性.

\section{Poisson分布}
\label{sec.distribution.poisson}
\textbf{离散分布}

\href{http://en.wikipedia.org/wiki/Poisson\_distribution}{wiki}

\textbf{泊松过程的特点}
\begin{enumerate}
\item Les nombres d'occurrences dans des intervalles de temps disjoints sont ind\'ependants
\item La probabilit\'e d'une occurrence dans un petit intervalle de temps est proportionnelle \`a la longueur de cet intervalle, le coefficient de proportionnalit\'e \'etant$ \lambda$
\item La probabilit\'e qu'il y ait plus d'une occurrence dans un petit intervalle de temps est n\'egligeable
\end{enumerate}
Ces deux derni\`eres conditions forment la propri\'et\'e dite des \textbf{\'ev\'enements rares}.

Math\'ematiquement, ces propri\'et\'es se traduisent, si l'on note $(N_{t})_{{t\in {\mathbb  {R}}^{+}}}$ le processus de Poisson et ${\mathbb  {P}}$ la probabilit\'e, par:
\begin{enumerate}
\item $\forall t_{0}=0\leq t_{1}<\dots <t_{k}$, les variables al\'eatoires $(N_{{t_{k}}}-N_{{t_{{k-1}}}}),\dots (N_{{t_{1}}}-N_{{t_{0}}})$ sont ind\'ependantes
\item ${\mathbb{P}}(N_{{t+h}}-N_{t}=1)=\lambda h+o(h)$ lorsque $h\to 0+$ (t \'etant fix\'e)
\item ${\mathbb{P}}(N_{{t+h}}-N_{t}>1)=o(h)$ lorsque $h\to 0+$ (t \'etant fix\'e)
\end{enumerate}

\begin{example}
在一个路口统计一个小时经过的车的流量.

设$X$表示一个小时经过这个路口的车辆的数量, 则$X$ 是一个随机变量, 记$E[X] = \lambda$
$$
\begin{aligned}
		&\text{泊松分布}  =  \text{二项分布}\\
		&\lambda  =  np \\
		&\lambda \ cars/hour   =  60\ min/hour \times \dfrac{\lambda}{60}\ cars/minute
\end{aligned}
$$
所以依据二项分布:
$$P(X=k) = C_{60}^k (\dfrac{\lambda}{60})^k (1 - \dfrac{\lambda}{60})^{60 - k}$$
但是上式成立的前提是\textbf{一分钟的时间粒度之内最多只能有一辆车}, 但是这肯定不符合实际情况.\\
那么怎么办呢? 我们可以不将一个小时划分为60个分钟, 而是划分为3600个秒, 那么这时:
$$\lambda\ cars/hour = 3600\ second/hour \times \dfrac{\lambda}{3600}\ cars/second$$
$$P(X=k) = C_{3600}^k (\dfrac{\lambda}{3600})^k (1 - \dfrac{\lambda}{3600})^{3600 - k}$$

但是, 我们可以继续按照这个逻辑提出质疑, 如果一秒钟之内有多辆车通过呢?\\
所以, 我们需要\textbf{无限细分},
$$P(X=k) = \lim_{n \to \infty}C_{n}^k (\dfrac{\lambda}{n})^k (1 - \dfrac{\lambda}{n})^{n - k}$$

通过这个example 我们可以看出泊松分布就是二项分布的极限情况.
\end{example}

泊松分布适合于描述单位时间内随机事件发生的次数的概率分布.如某一服务设施在一定时间内受到的服务请求的次数,电话交换机接到呼叫的次数,汽车站台的候客人数,机器出现的故障数,自然灾害发生的次数,DNA序列的变异数,放射性原子核的衰变数等等.

\bigskip
$X$ 表示在给定的时间间隔或指定区域$t$内结果的发生数量, 则泊松随机变量$X$的概率分布为:
$$
P(x,\lambda t)={\frac  {e^{-\lambda t}(\lambda t) ^{x}}{x!}}, \eqspace x=0,1,2,\cdots
$$
其中$\lambda$ 是单位时间(或单位面积)内随机事件的平均发生率,单位时间内得到结果的数量.


\begin{example}
一个试验中在$1 \mu s$ 内通过一计数器的平均辐射粒子数为4 个, 在某$1\mu s$ 中有6 个粒子通过计数器的概率为是多少?\\
根据参数, $x=6, \lambda t = 4 \times 1=4$, 得到
$$ p(6,4) = \frac{e^{-4} 4^6}{6!} = 0.1042 $$
\end{example}

\subsection{Features}	
\noindent
1.$E(X)=V(X)=\lambda$ \\
2.两个独立且服从泊松分布的随机变量,其和仍然服从泊松分布 (更精确地说:若$X \sim Poisson(\lambda_1)$且$Y \sim Poisson(\lambda_2)$,则 $X+Y \sim Poisson(\lambda_1+\lambda_2))$\\
3.与许多离散分布和连续分布一样, 随着均值越来越大, 泊松分布的形式越来越对称, 如图Figure~\ref{fig.distribution.poisson}.

\subsection{Poisson 分布与二项分布的关系}
%% http://my.oschina.net/u/347414/blog/129195
在二项分布的伯努利试验中,如果试验次数$n$很大,二项分布的概率$p$很小,且乘积$\lambda = n$ \\$p$比较适中,则事件出现的次数的概率可以用泊松分布来逼近.事实上,\textbf{二项分布可以看作泊松分布在离散时间上的对应物}.
\begin{proof}
证明如下.首先,回顾e的定义:
$$
\lim _{{n\to \infty }}\left(1-{\lambda  \over n}\right)^{n}=e^{{-\lambda }},
$$
二项分布的定义:
$$
P(X=k)={n \choose k}p^{k}(1-p)^{{n-k}}.
$$
如果令$p=\lambda /n$, $n$趋于无穷时$P$的极限:
$$
\begin{aligned}
\lim_{{n \to \infty }}P(X=k) & =\lim _{{n\to \infty }}{n \choose k}p^{k}(1-p)^{{n-k}}\\
& = \lim _{{n\to \infty }}{n! \over (n-k)!k!}\left({\lambda \over n}\right)^{k}\left(1-{\lambda \over n}\right)^{{n-k}}\\
& = \lim _{{n\to \infty }}\underbrace {\left[{\frac {n!}{n^{k}\left(n-k\right)!}}\right]}_{F}\left({\frac {\lambda ^{k}}{k!}}\right)\underbrace {\left(1-{\frac {\lambda }{n}}\right)^{n}}_{{\to \exp \left(-\lambda \right)}}\underbrace {\left(1-{\frac {\lambda }{n}}\right)^{{-k}}}_{{\to 1}}\\
& = \lim _{{n\to \infty }}\underbrace {\left[\left(1-{\frac {1}{n}}\right)\left(1-{\frac {2}{n}}\right)\ldots \left(1-{\frac {k-1}{n}}\right)\right]}_{{\to 1}}\left({\frac {\lambda ^{k}}{k!}}\right)\underbrace {\left(1-{\frac {\lambda }{n}}\right)^{n}}_{{\to \exp \left(-\lambda \right)}}\underbrace {\left(1-{\frac {\lambda }{n}}\right)^{{-k}}}_{{\to 1}}\\
& = \left({\frac {\lambda ^{k}}{k!}}\right)\exp \left(-\lambda \right)
\end{aligned}
$$
\end{proof}

\section{Beta 分布}
The probability density function of the \textbf{beta distribution}, for $0 \leq x \leq 1$, and shape parameters $\alpha, \beta > 0$, 

$$
\begin{aligned}
f(x;\alpha,\beta) & = \mathrm{constant}\cdot x^{\alpha-1}(1-x)^{\beta-1} \\
& = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{\int_0^1 u^{\alpha-1} (1-u)^{\beta-1}\, du} \\
& = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\, x^{\alpha-1}(1-x)^{\beta-1} \\
& = \frac{1}{Beta(\alpha,\beta)} x^{\alpha-1}(1-x)^{\beta-1}
\end{aligned}
$$

Beta 分布的概率密度我们把它画成图,会发现它是个百变星君,它可以是凹的,凸的,单调上升的,单调下降的,可以是曲线也可以是直线,
而均匀分布也是特殊的Beta分布.由于Beta 分布能够拟合如此之多的形状,因此它在统计数据拟合中被广泛使用.

\section{正态分布}
\textbf{连续概率分布}\\
若随机变量X服从一个位置参数为$\mu$ ,尺度参数为$\sigma$ 的概率分布,记为:$X\sim N(\mu ,\sigma ^{2})$

则其概率密度函数为
$$f(x)=\frac{1}{\sqrt{2\pi} \sigma} \exp({- \dfrac{(x-\mu )^{2}}{2\sigma ^{2}}})$$

如果$\sigma = 0$, 那么$X$ is contant and $X = \mu$

\begin{definition}
A r.v $X \in R^n$ is multivariant Gaussian if any linear combination of its compoents is uni Gaussian, i.e.
$$a^T X = \sum_{i=1}^n a_x X_i$$ is Gaussian
\end{definition}

$X \obey N(\mu, C)$ means $X$ is multi-variant Gaussian with $E(X_i) = \mu_i$ and $Cov(X_i, X_j) = C_{ij}$

\begin{definition}
$X \obey N(\mu, C)$ is degenerate if $\det{C} = 0$
\end{definition}
(这个时候会成为一个放射线)

\href{http://www.ryanzhang.info/wp-content/uploads/2013/07/QQ\%E6\%88\%AA\%E5\%9B\%BE20130706200349.png}{协方差矩阵对多元高斯分布的影响}\\
上图是5个不同的模型,从左往右依次分析:
\begin{enumerate}
\item 是一个一般的二元高斯分布模型(independent, 同时expectation 相等)
\item 通过协方差矩阵,令特征1拥有较小的偏差,同时保持特征2的偏差
\item 通过协方差矩阵,令特征2拥有较大的偏差,同时保持特征1的偏差
\item 通过协方差矩阵,在不改变两个特征的原有偏差的基础上,增加两者之间的正相关性
\item 通过协方差矩阵,在不改变两个特征的原有偏差的基础上,增加两者之间的负相关性
\end{enumerate}

图4:\\
valeur propre:
$\lambda_1 = 1.5$,\
$\lambda_2 = 0.5$\\
vecteur propre:
$v_1 = (0.7, 0.7)^T$,\
$v_2 = (-0.7, 0.7)^T$

图5:\\
valeur propre:
$\lambda_1 = 1.8$,\
$\lambda_2 = 0.2$\\
vecteur propre:
$v_1 = (-0.7, 0.7)^T$,\
$v_2 = (-0.7, -0.7)^T$

从这两组数据中, 我们看出vector propre的方向为椭圆的轴向, valeur propre为相应的半轴的大小

\begin{theorem}
\textbf{independent compoents}\\
$\vector{X}$ are \textbf{independent} with $X_i \obey N(\mu_i, \sigma_i^2)$ iff $X = (\vector{X}) \obey N(\mu, C)$ where
$$\mu = (\vector{\mu}) \hbox{ and } C = \diag{\vector{\sigma^2}}$$
\label{theorem.gauss.indepent_component}
\end{theorem}

\warning{$\vector{X}$ each uni Gaussian $\nRightarrow X = (\vector{X})$ is multi Gaussian}\\
因为这些components 可以是相关的, 例如下面的counter-example, 所以非相关是上面的定理\ref{theorem.gauss.indepent_component}必要条件.
\begin{example}
$X_1 \obey N(0,1)$ and
$$
X_2 =
    \left\{
       \begin{array}{ll}
          X_1, & |X_1| \leq 1 \\
          - X_1, & |X_1| > 1
        \end{array}
    \right.
$$
由于$X_1$是标准正态分布(对称的), 所以画图可以看出$X_2$也是标准高斯分布,\\
但是$X=(X_1, X_2)$ 不是multi-variant Gaussian.\\
将$X_1, X_2$画在一个图上\href{http://i.imgbox.com/gmRq7VFK.png}{$X_1, X_2$的图}, 我们可以很清楚的看到向量$X$不是一个二维的高斯分布.
\end{example}

\begin{theorem}
If $X \in R^n$ is Gaussian then $X_i, X_j$ are indenpendent iff $Cov(X_i, X_j) = 0$
\end{theorem}
\warning{This does not hold for Non-Gaussian}

\begin{theorem}
A Gaussian random vector(column vector) $X \obey N(\mu, C)$ has a \textbf{density} iff it is non-degenrate(i.e. $\det{C} \neq 0$)
$$
f(x) = \frac{1}{(2\pi)^{n/2} \det{C}^{1/2}} \exp[- \frac{(x - \mu)^T C^{-1} (x - \mu)}{2}]
$$
\end{theorem}
我们也可以将PDF写为:
$$
f(x) = \frac{1}{\sqrt{\det{2 \pi C}}} \exp[- \frac{(x - \mu)^T C^{-1} (x - \mu)}{2}]
$$
我们注意到$\det{C} \neq 0$, 所以$C$ 可逆, 也就是说$C^{-1}$ 存在.

\begin{theorem}
\textbf{Affine property}\\
Any affine transformation($f(x) = ax + b$) of a Gaussian is Gaussian. That is if $X \obey N(\mu, C)$, then
$$AX+b \obey N(A\mu + b, ACA^T)$$
$\forall \mu \in R^n, C \in R^{n \times n}, A \in R^{n \times n}, b \in R^n$
\end{theorem}

\begin{fact}
\textbf{Construction}\\
$\vector{X} \obey N(0,1)$ indep $\Rightarrow X \obey N(0, I)$
$\Rightarrow AX + \mu \obey N(\mu, C)$ where $C = A A^T, \forall \mu \in R^n, A \in R^{n \times n}$
\end{fact}

\begin{fact}
\textbf{Sphering, oppsite of construction}\\
If $C$ is simi-definie positif, then:
$$Y \obey N(\mu, C) \Rightarrow A^{-1}(Y - \mu) \obey N(0,I)$$
where $C = A A^T$
\end{fact}

\subsection{Geometric intuition for the multivariate Gaussian}
Let $X \obey N(0,1), C $ the covariance matrix and $\mu \in R^n$\\
$C$ est sym\'etrique, donc diagonalisable.
$$
C = U P U^T = U P^{1/2} P^{1/2} U^T = (U P^{1/2}) (U P^{1/2})^T =  A A^T
$$
$U = (\vector{u})$ matrice orthogonal(orthogonal signifie que $U^T = U^{-1}$), est une \textbf{matrice reflexion ou rotation}.\\
$P$ martice diagonal et $P = \diag{\vector{\lambda}}$

证明$\lambda_i \geq 0$
\begin{proof}
$$Cu = \lambda u \Rightarrow u^T C u = u^T \lambda u = \lambda \ps{u}{u} \Rightarrow Cov(u,u) = \lambda \ps{u}{u} \geq 0 \Rightarrow \lambda \geq 0$$
\end{proof}

Let $Y = A X + \mu = U P^{1/2} X + \mu \Rightarrow Y \obey N(\mu, C)$

\href{http://i.imgbox.com/9t3eUww4.png}{几何图形演示从$X$到$AX$再到$AX+\mu$的变化过程}\\
图中的$\wedge$ 就是这里的矩阵$P$

eg: $n = 2$\\
$$
U P^{1/2} X
=
(u_1, u_2)
\times
\begin{pmatrix}
\sigma_1 & 0 \\
0 & \sigma_1
\end{pmatrix}
\times
\begin{pmatrix}
x_1\\
x_2
\end{pmatrix}
=
\sigma_1 x_1 u_1 + \sigma_2 x_2 u_2
$$
考虑到
$$
\begin{pmatrix}
x_1\\
x_2
\end{pmatrix}
=
1 \times x_1
\begin{pmatrix}
1\\
0
\end{pmatrix}
+
1 \times x_2
\begin{pmatrix}
0\\
1
\end{pmatrix}
$$
两者对比发现, 我们可以得出以下结论:
\begin{enumerate}
\item vector propre 的方向为椭圆的轴向
\item valeur propre 为相应的半轴的大小
\end{enumerate}

\subsection{Gaussian marginal and conditionals}
\begin{theorem}
$X = (X_1, X_2)^T \in R^2$ Gaussian $\Rightarrow X_1, X_2$ Gaussian
\end{theorem}
将多维高斯分布投影到坐标轴上, 仍然是高斯分布.
\begin{proof}
$$A = (1, 0) \Rightarrow AX = X_1$$
$$X \obey N(\mu, C) \Rightarrow AX = X_1 \obey N(A\mu, ACA^T)$$
\end{proof}

\begin{theorem}
$X = (X_1, X_2)^T \in R^2$ Gaussian $\Rightarrow (X_1 | X_2 = x_2)$ Gaussian
\end{theorem}

\bigskip
Let $X \obey N(\mu, C), a = (1,2,\ldots, k), b = (k+1, \ldots, n), k \in [1,n]$\\
$$
X =
\begin{pmatrix}
    X_a \\
    X_b \\
\end{pmatrix}
,
X_a =
\begin{pmatrix}
    X_1 \\
    \vdots \\
    X_k \\
\end{pmatrix}
,
X_b =
\begin{pmatrix}
  X_{k+1} \\
  \vdots \\
  X_n \\
\end{pmatrix}
,
\mu =
\begin{pmatrix}
  \mu_a \\
  \mu_b \\
\end{pmatrix}
$$

$$
C =
\begin{pmatrix}
  C_{aa} & C_{ab} \\
  C_{ba} & C_{bb} \\
\end{pmatrix}
,
\
C_{aa} =
\begin{pmatrix}
  C_{11} & \cdots & C_{1k} \\
  \vdots & \ddots & \vdots \\
  C_{k1} & \cdots & C_{kk} \\
\end{pmatrix}
$$
\begin{fact}
\textbf{Marginal property}\\
$$X_a \obey N(\mu_a, C_{aa})$$
\end{fact}
\begin{proof}
构造一个projection matrix:
\newcommand\bigzero{\makebox(0,0){\text{\huge0}}}
$$
A =
\begin{bmatrix}
    1 &  &  &  &  &&\\
 	  & 1 &  & \bigzero & &&\\
      &   & \ddots &  &  &\bigzero& \\
      & \bigzero & & 1 &  &&\\
      &   &   & & 1 &&\\
\end{bmatrix}_{k \times n}
=
\begin{bmatrix}
	I_{k \times k} & 0_{k \times (n-k)}
\end{bmatrix}
$$

容易证明: $$AX = {X_a}, A\mu = \mu_a, ACA^T = C_{aa}$$
$$AX \obey N(A\mu, ACA^T) = N(\mu_a, C_{aa})$$
\end{proof}

\begin{fact}
\textbf{Conditional property}\\
$(X_a|X_b = x_b) \obey N(m, D)$ where
$$m = \mu_a + C_{ab} C_{bb}^{-1}(x_b - \mu_b)$$
$$D = C_{aa} - C_{ab} C_{bb}^{-1} C_{ba}$$
\end{fact}

\begin{theorem}
If $X \in R^n \obey N(\mu_X, C_X)$, $Y \in R^n \obey N(\mu_Y, C_Y)$
indep, then
$$X + Y \obey N(\mu_X + \mu_Y, C_X + C_Y)$$
\end{theorem}
\begin{proof}
当 $n=1$时, $X, Y$ 独立的高斯分布, 所以依据定理\ref{theorem.gauss.indepent_component}, $(X, Y)$ 为二元高斯分布, 根据多元高斯分布的定义(分量的线性组合仍为高斯分布), 所以$X+Y$为高斯分布\\
for the general case, $a^T (X+Y) = a^T X + a^T Y$
\end{proof}
由于$X,Y$相互独立, 所以\\
$E[X+Y] = E[X] + E[Y]$\\
由于$Cov(X) = E[XX^T] - E[X] E[X]^T$, (Note: $(E[X])^T = E[X^T]$)
$$
\begin{aligned}
& Cov(X+Y) \\
& = E[(X+Y)(X+Y)^T] - E[X+Y] E[X+Y]^T \\
& = E[X X^T + X Y^T + Y X^T + Y Y^T] - (E[X] + E[Y]) (E[X]^T+ E[Y]^T) \\
& = (E[X X^T] + E[X Y^T] + E[Y X^T] + E[Y Y^T]) - (E[X] E[X]^T + E[X] E[Y]^T + E[Y] E[X]^T + E[Y] E[Y]^T) \\
& = (E[X X^T] + E[X] E[Y^T] + E[Y] E[X^T] + E[Y Y^T]) - (E[X] E[X]^T + E[X] E[Y]^T + E[Y] E[X]^T + E[Y] E[Y]^T) \\
& = (E[X X^T] - E[X] E[X]^T) +  (E[Y Y^T] - E[Y] E[Y]^T) \\
& = Cov(X) + Cov(Y)
\end{aligned}
$$
\subsection{中心极限定理}
正态分布有一个非常重要的性质:
在特定条件下,大量统计独立的随机变量的平均值的分布趋于正态分布,这就是中心极限定理.中心极限定理的重要意义在于,根据这一定理的结论,其他概率分布可以用正态分布作为近似.

Le th\'eor\`eme central limite \'etablit la convergence en loi de la somme d'une suite de variables al\'eatoires vers la loi normale.
Intuitivement, ce r\'esultat affirme que toute somme de variables al\'eatoires ind\'ependantes et identiquement distribu\'ees tend vers
une variable al\'eatoire gaussienne.

Soit $X_1, X_2, \cdots$ une suite de variables al\'eatoires r\'eelles d\'efinies sur le m\^eme espace de probabilit\'e, ind\'ependantes et identiquement distribu\'ees suivant la m\^eme loi $D$. Supposons que l'esp\'erance $\mu$ et l'\'ecart-type $\sigma$ de $D$ existent et soient finis avec $\sigma \neq 0$.

Consid\'erons la somme
$$S_n = X_1 + X_2 + \cdots + X_n$$
Alors l'esp\'erance de $S_n$ est $n\mu$ et
son \'ecart-type vaut $\sigma \sqrt{n}$.
De plus, quand $n$ est assez grand, la loi normale $\mathcal{N}(n \mu,n \sigma^2)$ est une bonne approximation de la loi de $S_n$.

Afin de formuler math\'ematiquement cette approximation, nous allons poser
$$ X_n = S_n/n = (X_1 + X_2 + \cdots + X_n)/n $$
et
$$ \mathrm{Z}_n = \frac{\mathrm{S}_n - n \mu}{\sigma \sqrt{n}} = \frac{\overline{\mathrm{X}}_n - \mu}{\sigma/\sqrt{n}}, $$
de sorte que l'esp\'erance et l'\'ecart-type de $Zn$ valent respectivement $0$ et $1$ : la variable est ainsi dite centr\'ee et r\'eduite.

Le th\'eor\`eme central limite stipule alors que la suite de variables al\'eatoires $Z1, Z2,..., Zn,... $converge en loi vers une variable al\'eatoire $Z$,
d\'efinie sur le m\^eme espace probabilis\'e, et de loi normale centr\'ee r\'eduite $\mathcal{N} (0, 1)$ lorsque $n$ tend vers l'infini.

参数为$n$和$p$的二项分布,在$n$相当大而且$p$接近$0.5$时近似于正态分布(有的参考书建议仅在$np$与$n(1-p)$至少为5时才能使用这一近似).
近似正态分布平均数为$\mu =np$且方差为$\sigma ^{2}=np(1-p)$.

泊松分布带有参数$\lambda$ 当取样样本数很大时将近似正态分布$\lambda$ .
近似正态分布平均数为$\mu =\lambda$ 且方差为$\sigma ^{2}=\lambda$ .

这些近似值是否完全充分正确取决于使用者的使用需求.

\section{重尾分布}
在机率论中,重尾分布(英语:Heavy-tailed distribution)是一种机率分布的模型,它的尾部比指数分布还要厚.
在许多状况中,通常右边尾部的分布会比较受到重视,但左边尾部比较厚,或是两边尾部都很厚的状况,也会被认为是一种重尾分布.

重尾分布之中,又有两个子类型,分别称为长尾分布(long-tailed distributions)以及次指数分布(subexponential distributions).

在一个累积分布函数中,一个随机变量 $X$　的分布状况,在以下状况时,被称为是一个重尾分布.假设:
$$ \lim_{x \to \infty} e^{\lambda x}\Pr[X>x] = \infty \quad \mbox{for all } \lambda>0 $$

在一个累积分布函数中,一个随机变量 $X$的分布,出现以下状况时,被称为是一个长尾分布.假设对所有$t > 0$ :
$$ \lim_{x \to \infty} \Pr[X>x+t|X>x] =1$$
对一个右尾部形成长尾分布的状况,我们可以做一个直观的解释:假如一个长尾分布的尾部数量超过某个很高的水平,它超过另一个更高水平的机率会接近于一.
也就是说,如果你发现状况很糟,它可能会比你想像的还要糟.\\
长尾分布是重尾分布中的一个特例.所有的长尾分布都是重尾分布,但反之则不然,也就是说,我们可以找出某一个重尾分布,它不是长尾分布.

\subsection{Loi des grands nombres}
On consid\`ere une suite $(X_n)_{n\in\N^*}$ de variables al\'eatoires ind\'ependantes d\'efinies sur un m\^eme espace probabilis\'e,
ayant m\^eme variance finie et m\^eme esp\'erance not\'ees respectivement $V(X)$ et $E(X)$.

La loi faible des grands nombres stipule que, pour tout r\'eel $\epsilon$ strictement positif, la probabilit\'e que la moyenne empirique
$Y_n \equiv \bar x= \frac{1}{n} \sum_{i=1}^{n} X_i$ s'\'eloigne de l'esp\'erance d'au moins $\epsilon$ tend vers $0$ quand $n$ tend vers l'infini.

\begin{theorem}
$\forall\varepsilon>0,\quad \lim_{n \to +\infty} \mathbb{P}\left(\left|\frac{X_1+X_2+\cdots+X_n}{n} -E(X)\right| \geqslant \varepsilon\right) = 0$
\end{theorem}

Autrement dit, $(Y_n)_{n\in\N^*}$ converge en probabilit\'e vers $E(X)$. Ce r\'esultat est tr\`es important en statistique,
puisqu'il assure que la moyenne empirique est un estimateur convergent de l'esp\'erance.

\section{Estimation}
Pour caract\'eriser l'estimation de $\theta$, on verra les crit\`eres suivants:
\begin{itemize}
\item Convergence lorsque $n \to \infty$ (forte consistence)
\item Convergence en moyenne (biais)
\item Maximisation probabiliste (maximum de vraisemblance)
\item Crit\`ere bas\'e sur la variance (risque)
\end{itemize}

\begin{definition}
\textbf{Biais d'un estimateur}:
La diff\'erence entre l'esp\'erance de l'estimateur et la vraie valeur du param\`etre estim\'e.

Si $\hat \theta$ est l'estimateur de $\theta\,,  \text{Biais}(\hat\theta)\equiv E[\hat\theta]-\theta$
\end{definition}

\subsection{Maximum de vraisemblance}
极大似然原理的直观想法是:一个随机试验如有若干个可能的结果$A,B,C,\cdots$.若在一次试验中,结果$A$出现,则一般认为试验条件对A出现有利,也即$A$出现的概率很大.

最大似然估计会寻找关于$\theta$的最可能的值(即,在所有可能的$\theta$取值中,寻找一个值使这个采样的"可能性"最大化).
这种方法正好同一些其他的估计方法不同,如$\theta$的非偏估计,非偏估计未必会输出一个最可能的值,而是会输出一个既不高估也不低估的$\theta$值.

Soit une famille param\'etr\'ee de distributions de probabilit\'es $D_{\theta}$ dont les \'el\'ements sont associ\'es soit
\`a une densit\'e de probabilit\'e connue (distribution continue), soit \`a une fonction de masse connue (distribution discr\`ete), not\'ee $f_{\theta}$.
On tire un \'echantillon de $n$ valeurs $x_1, x_2, \cdots, x_n$:de la distribution,
et l'on calcule la densit\'e de probabilit\'e associ\'ee aux donn\'ees observ\'ees

$$ f_\theta(x_1,\dots,x_n \mid \theta).\, $$
Ceci \'etant une fonction de $\theta$ avec $x_1, \cdots, x_n$ fix\'es, c'est une vraisemblance.

$$ L(\theta) = f_\theta(x_1,\dots,x_n \mid \theta).\, $$
Lorsque $\theta$ n'est pas observable, la m\'ethode du maximum de vraisemblance utilise les valeurs de $\theta$ qui
maximisent $L(\theta)$ estimateur de $\theta$: c'est l'estimateur du maximum de vraisemblance de $\theta$ not\'e $\widehat{\theta}$.
Par exemple dans le cas du produit discret, on effectue un tirage de n valeurs,
il faut donc trouver le param\`etre qui maximise la probabilit\'e d'avoir tir\'e ce tirage.

\bigskip
On appelle vraisemblance de $\theta$ au vu des observations $(x_1, \ldots,x_i, \ldots, x_n)$ d'un \'echantillon ind\'ependamment et identiquement distribu\'e
selon la loi $\mathcal{D}_\theta$, le nombre :
$$ L(x_1, \ldots,x_i, \ldots,x_n;\theta) = f(x_1;\theta) \times f(x_2;\theta) \times \ldots \times f(x_n;\theta) = \prod_{i=1}^n f(x_i;\theta) $$

On cherche à trouver le maximum de cette vraisemblance pour que les probabilit\'es des r\'ealisations observ\'ees soient aussi maximum.
Ceci est un probl\`eme d'optimisation.

On utilise g\'en\'eralement le fait que si L est d\'erivable (ce qui n'est pas toujours le cas) et
si L admet un maximum global en une valeur $\theta = \hat \theta$,
alors la d\'eriv\'ee premi\`ere s'annule en $\theta = \hat \theta $et que la d\'eriv\'ee seconde est n\'egative. \\
R\'eciproquement, si la d\'eriv\'ee premi\`ere s'annule en $\theta = \hat \theta$ et que la d\'eriv\'ee seconde est n\'egative en $\theta = \hat \theta$,
alors $\theta = \hat \theta $est un maximum local (et non global) de $L(x_1, \ldots, x_i, \ldots,x_n;\theta)$. \\
Il est alors n\'ecessaire de v\'erifier qu'il s'agit bien d'un maximum global.
La vraisemblance \'etant positive et le logarithme n\'ep\'erien(naturel) une fonction croissante,
il est \'equivalent et souvent plus simple de maximiser le logarithme n\'ep\'erien de la vraisemblance.

Ainsi en pratique:

La condition n\'ecessaire
$$ \frac{\partial L(x_1, \ldots, x_i, \ldots, x_n;\theta)}{\partial \theta} = 0 $$
ou
$$ \frac{\partial \ln L(x_1, \ldots, x_i, \ldots, x_n;\theta)}{\partial \theta} = 0 $$
permet de trouver la valeur $\theta = \hat \theta$.
$\theta = \hat \theta $est un maximum local si la condition suffisante est remplie au point critique $\theta = \hat \theta $:
$$ \frac{\partial^2 L(x_1, \ldots, x_i, \ldots, x_n;\theta)}{\partial \theta^2} \le 0 $$
ou
$$ \frac{\partial^2 \ln L(x_1, \ldots, x_i, \ldots,x_n;\theta)}{\partial \theta^2} \le 0 $$

\subsubsection{Likelihood function}
The likelihood function is defined differently for discrete and continuous probability distributions.

\textbf{Discrete probability distribution}\\
Let $X$ be a random variable with a discrete probability distribution p depending on a parameter $\theta$. Then the function

$$ \mathcal{L}(\theta |x) = p_\theta (x) = P_\theta (X=x), \, $$
considered as a function of $\theta$, is called the likelihood function (of $\theta$, given the outcome $x$ of $X$).

Sometimes the probability on the value $x$ of $X$ for the parameter value $\theta$ is written as $P(X=x|\theta)$; often written as $\mathbf{P(X=x;\theta)}$ to emphasize that this value is \textbf{not a conditional probability}, because \textbf{$\theta$ is a parameter and not a random variable}.

\textbf{Continuous probability distribution}\\
Let $X$ be a random variable with a continuous probability distribution with density function $f$ depending on a parameter $\theta$. Then the function
$$ \mathcal{L}(\theta |x) = f_{\theta} (x), \, $$
considered as a function of $\theta$, is called the likelihood function (of $\theta$, given the outcome $x$ of $X$).

Sometimes the density function for the value $x$ of $X$ for the parameter value $\theta$ is written as $f(x|\theta)$,
but should not be considered as a conditional probability density.

The actual value of a likelihood function bears no meaning. Its use lies in comparing one value with another.
For example, one value of the parameter may be more likely than another, given the outcome of the sample.
Or a specific value will be most likely: the maximum likelihood estimate.

\begin{example}
考虑投掷一枚硬币的实验.通常来说,已知投出的硬币正面朝上和反面朝上的概率各自是$p_H = 0.5$,便可以知道投掷若干次后出现各种结果的可能性.
比如说,投两次都是正面朝上的概率是0.25.用条件概率表示,就是:
$$ P(\mbox{HH} \mid p_H = 0.5) = 0.5^2 = 0.25 $$
其中H表示正面朝上.

在统计学中,我们关心的是在已知一系列投掷的结果时,关于硬币投掷时正面朝上的可能性的信息.
我们可以建立一个统计模型:假设硬币投出时会有$p_H$  的概率正面朝上,而有$1 - p_H$ 的概率反面朝上.
这时,条件概率可以改写成似然函数:
$$ L(p_H =  0.5 \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = 0.5) =0.25 $$
也就是说,对于取定的似然函数,在观测到两次投掷都是正面朝上时,$p_H = 0.5$ 的似然性是0.25(这并不表示当观测到两次正面朝上时$p_H= 0.5$ 的概率是0.25).

如果考虑$p_H = 0.6$,那么似然函数的值也会改变.
$$ L(p_H = 0.6 \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = 0.6) =0.36 $$
注意到似然函数的值变大了.\\
这说明,如果参数$p_H$ 的取值变成0.6的话,结果观测到连续两次正面朝上的概率要比假设$p_H = 0.5$ 时更大.也就是说,参数$p_H$ 取成0.6 要比取成0.5 更有说服力,更为"合理".
\\(这里的$p_H$ 就是似然函数中的$\theta$, 而连续两次正面朝上HH 就是似然函数中随机变量$X$取得$x$.)

总之,\textbf{似然函数的重要性不是它的具体取值,而是当参数变化时函数到底变小还是变大}.
对同一个似然函数,如果存在一个参数值,使得它的函数值达到最大的话,那么这个值就是最为"合理"的参数值.

在这个例子中,似然函数实际上等于:
$$ L(p_H = \theta  \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = \theta) =\theta^2 , 其中0 \le p_H  \le 1.  $$
如果取$p_H = 1$,那么似然函数达到最大值1.也就是说,当连续观测到两次正面朝上时,假设硬币投掷时正面朝上的概率为1是最合理的.

类似地,如果观测到的是三次投掷硬币,头两次正面朝上,第三次反面朝上,那么似然函数将会是:
$$ L(p_H = \theta  \mid \mbox{HHT}) = P(\mbox{HHT}\mid p_H = \theta) =\theta^2(1 - \theta) , 其中T表示反面朝上,0 \le p_H  \le 1.  $$
这时候,似然函数的最大值将会在$p_H = \frac{2}{3}$的时候取到.\\
也就是说,当观测到三次投掷中前两次正面朝上而后一次反面朝上时,估计硬币投掷时正面朝上的概率$p_H = \frac{2}{3}$是最合理的.
\end{example}

\subsection{Borne Cram\'er-Rao}
la borne Cram\'er-Rao exprime une borne inf\'erieure sur la variance d'un estimateur sans biais, bas\'ee sur l'Information de Fisher.
Elle \'enonce que l'inverse de l'information de Fisher, $\mathcal{I}(\theta)$, d'un param\`etre $\theta$,
est une borne inf\'erieure de la variance d'un estimateur sans biais de ce param\`etre (not\'e $\widehat{\theta}$).
$$
\mathrm{var} \left(\widehat{\theta}\right)
\geq
\mathcal{I}(\theta)^{-1}
= \mathbb{E}
 \left[
   \left(\frac{\partial}{\partial \theta} \ln L(X;\theta)\right)^2
 \right]^{-1}
$$

\begin{example}
Supposons que $X$ est un vecteur al\'eatoire qui suit une loi normale d' esp\'erance connue $\mu$ et de variance inconnue $\sigma^2$.
Consid\'erons $T$ l'estimateur de $\sigma^2$:

$$ T=\frac{\sum_{i=1}^n\left(X_i-\mu\right)^2}{n}.  $$
Alors $T$ est non biais\'e pour $\sigma^2$, car $E[T]=\sigma^2$. Quelle est la variance de $T$ ?

$$
\mathrm{Var}(T) = \frac{\mathrm{var}(X-\mu)^2}{n}=\frac{1}{n}
\left[
E\left\{(X-\mu)^4\right\}-\left(E\left\{(X-\mu)^2\right\}\right)^2
\right]
$$
\todo{上式的第一个等号有点不理解}
$$(Var(X) = E(X^2) - (E(X))^2)$$
Le premier terme est le quatri\`eme moment centr\'e et vaut $3\sigma^4$; le second est le carr\'e de la variance, soit $\sigma^4$. Donc :

$$ \mathrm{var}(T)=\frac{2\sigma^4}{n}.  $$
Quelle est l'information de Fisher de cet exemple ? Le score $V$ est d\'efini par :


$$ V=\frac{\partial}{\partial\sigma^2}\log L(\sigma^2,X) $$
avec L \'etant la fonction de vraisemblance. Donc, dans ce cas,

$$
V=\frac{\partial}{\partial\sigma^2}\log\left[\frac{1}{\sqrt{2\pi\sigma^2}}e^{-(X-\mu)^2/{2\sigma^2}}\right]
=\frac{(X-\mu)^2}{2(\sigma^2)^2}-\frac{1}{2\sigma^2}
$$
L'information de $n$ \'ev\`enements ind\'ependants \'etant seulement $n$ fois l'information d'un seul \'ev\`enement, soit $\frac{n}{2(\sigma^2)^2}$.

L'in\'egalit\'e de Cram\'er-Rao donne :
$$ \mathrm{var}(T)\geq\frac{1}{I}.$$
Dans ce cas, on a donc \'egalit\'e, ce qui montre que l'estimateur est efficace.
\end{example}

\section{Fisher information}
The Fisher information is a way of \textbf{measuring the amount of information that an observable random variable $X$
carries about an unknown parameter $\theta$ upon which the probability of $X$ depends}.

The probability function for $X$, which is also the likelihood function for $\theta$, is a function $f(X; \theta)$;
it is the probability mass (or probability density) of the random variable $X$ conditional on the value of $\theta$.

The partial derivative with respect to $\theta$ of the natural logarithm of the likelihood function is called the \textbf{score}.\\
(In statistics, the score, score function, efficient score or informant indicates \textbf{how sensitively a likelihood function $L(\theta; X)$
depends on its parameter $\theta$}.
Explicitly, the score for $\theta$ is the gradient of the log-likelihood with respect to $\theta$: $\dfrac{\partial}{\partial\theta} \log L(\theta;X)$.)

Under certain regularity conditions, it can be shown that the first moment of the score (that is, its expected value) is $0$:
$$
\begin{aligned}
\operatorname{E} \left[\left. \frac{\partial}{\partial\theta} \log f(X;\theta)\right|\theta \right]
& = \operatorname{E} \left[\left. \frac{\frac{\partial}{\partial\theta} f(X;\theta)}{f(X; \theta)}\right|\theta \right]\\
& = \int \frac{\frac{\partial}{\partial\theta} f(x;\theta)}{f(x; \theta)} f(x;\theta)\; \mathrm{d}x\\
& = \int \frac{\partial}{\partial\theta} f(x;\theta)\; \mathrm{d}x\\
& = \frac{\partial}{\partial\theta} \int f(x; \theta)\; \mathrm{d}x\\
& = \frac{\partial}{\partial\theta} \; 1 \\
& = 0.
\end{aligned}
$$

The second moment is called the Fisher information:
$$
\mathcal{I}(\theta)=\operatorname{E} \left[\left. \left(\frac{\partial}{\partial\theta} \log f(X;\theta)\right)^2\right|\theta \right] = \int \left(\frac{\partial}{\partial\theta} \log f(x;\theta)\right)^2 f(x; \theta)\; \mathrm{d}x\,,
$$
where, for any given value of $\theta$, the expression $E[...|\theta]$ denotes the conditional expectation over values for $X$ with respect to the probability function $f(x; \theta)$ given $\theta$. Note that $0 \leq \mathcal{I}(\theta) < \infty$.

A random variable carrying high Fisher information implies that the absolute value of the score is often high.
The Fisher information is not a function of a particular observation, as the random variable $X$ has been averaged out.

Since the expectation of the score is zero, the Fisher information is also the variance of the score.

If $\log f(x; \theta)$ is \textbf{twice differentiable with respect to $\theta$}, and under certain regularity conditions,
then the Fisher information may also be written as[10]

$$ \mathcal{I}(\theta) = - \operatorname{E} \left[\left. \frac{\partial^2}{\partial\theta^2} \log f(X;\theta)\right|\theta \right]\,, $$
since

$$
\frac{\partial^2}{\partial\theta^2} \log f(X;\theta)
= \frac{\frac{\partial^2}{\partial\theta^2} f(X;\theta)}{f(X; \theta)}
\;-\;
\left( \frac{\frac{\partial}{\partial\theta} f(X;\theta)}{f(X; \theta)} \right)^2
= \frac{\frac{\partial^2}{\partial\theta^2} f(X;\theta)}{f(X; \theta)}
\;-\;
\left( \frac{\partial}{\partial\theta} \log f(X;\theta)\right)^2
$$
and

$$
\operatorname{E} \left[\left. \frac{\frac{\partial^2}{\partial\theta^2} f(X;\theta)}{f(X; \theta)}\right|\theta \right]
= \cdots
= \frac{\partial^2}{\partial\theta^2} \int f(x; \theta)\; \mathrm{d}x
= \frac{\partial^2}{\partial\theta^2} \; 1
= 0.
$$
Thus, the Fisher information is the negative of the expectation of the second derivative with respect to $\theta$ of the natural logarithm of $f$.

Information is \textbf{additive}, in that the information yielded by two independent experiments is the sum of the information from each experiment separately:
$$ \mathcal{I}_{X,Y}(\theta) = \mathcal{I}_X(\theta) + \mathcal{I}_Y(\theta) $$
This result follows from the elementary fact that if random variables are independent, the variance of their sum is the sum of their variances.
In particular, the information in a random sample of size $n$ is $n$ times that in a sample of size 1,
when observations are independent and identically distributed.

\section{PCA: Principal component analysis}
降维技术使得数据更易使用, 并且他们能够去除数据中的噪声, 使得其他机器学习任务更加精确. 降维往往作为预处理步骤, 在数据应用其他算法之前清洗数据.\\
有很多技术可以用于数据降维, 独立成分分析(Independent Component Analysis, ICA), 因子分析(Factor Analysis)和主成分分析比较流行, 其中又以主成分分析应用最广泛.\\
机器学习实战一书中的python 实例是将数据集都调入内存, 如果无法做到, 就需要采用其他的方法, 可以参考一篇优秀的论文 - Incremental Eigenanalysis for Classification

a useful statistical technique

wiki: the frist principal component has the largest possible variance.\\
\noindent
用covariance matrix 矩阵来讲解的话, 说是最大的eigenvalue 对应的eigenvector所在方向为the most principal component方向\\
\red{机器学习实战中说, 求得的特征值若为零, 则意味着这些特征值是其他特征的副本, 也就是, 他们可以通过其他特征来表示, 没有理解todo}

Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.

PCA can be done by eigenvalue decomposition of a data covariance (or correlation) matrix or singular value decomposition of a data matrix, usually after mean centering (and normalizing or using Z-scores) the data matrix for each attribute.

PCA is the simplest of the true eigenvector-based multivariate analyses. Often, its operation can be thought of as revealing the internal structure of the data in a way that best explains the variance in the data.

\subsection{Idea}
我们以二元变量$X = (X_1, X_2)$为例, 说明主成分分析的思想. 对此二维变量进行了$n$ 次观测, 得到数据$x_i = (x_{i1},x_{i2}) \eqspace (i=1,2,\dots,n))$.假设它们在二维平面x1ox2上的分布如Figure
\href{http://upload.wikimedia.org/wikipedia/commons/thumb/1/15/GaussianScatterPCA.png/220px-GaussianScatterPCA.png}{PCA idea}
所示.

考虑如下一种极端情况,即$X_1$和$X_2$的相关系数的绝对值为$1$,则$(x(i_1),x(i_2))(i=1,2,...n)$以概率$1$分布在一条直线$L$上,若将原坐标系沿逆时针方向旋转一个角度$\theta $得到新的直角坐标系$y_1oy_2$,使坐标轴$oy_1$与$L$重合,这时观测点$(x(i_1),x(i_2))(i=1,2,...n)$则可由它们在$oy_1$上的坐标所决定,这些观测点在$oy_1$上的坐标为
$$ y(i_1)=x(i_1)cos\theta +x(i_2)sin\theta ,    i=1,2,...n $$
它们是原观测数据的线性组合且在$oy_1$轴上的分散性(即样本方差)达到最大. 这相当于对原变量$(X_1,X_2)$作适当的线性变换得新的变量$Y_1$,即
$$ Y_1=X_1cos\theta +X_2sin\theta , $$
其中$\theta $的选择使得$Var(Y_1)$最大且$Y_1$的相应观测值完全可以反映原二元变量$(X_1,X_2)$的观测值的分布状况. 一般情况下,将$ox_1$轴沿逆时针旋转到观测点具有最大分散性的方向$oy_1$上(观测点在$oy_1$轴上的投影到均值点的距离大于在$ox_1$上投影到均值点的距离),使该方向所含的数据间的差异的信息最多. 同样的,再旋转$ox_2$到$oy_2$. 我们将相应的变量
$$ Y_1=X_1cos\theta +X_2sin\theta , $$
$$ Y_2=X_1sin\theta +X_2cos\theta , $$
分别称为$X_1$和$X_2$的第一和第二主成分. 设想数据在$oy_2$方向上的分散性很小,因而用一元数据便可以反映二元数据的绝大部分信息,即达到了降维的目的.
综上所述,主成分分析是研究如何通过少数几个主成分来解释多变量的方差-协方差结构的分析方法,也就是求出少数几个主成分(变量) ,使它们尽可能多地保留原始变量的信息,且彼此不相关. 它是一种变换方法,即把给定的一组变量通过线性变换,转换为一组不相关的变量,在这种变换中,\textbf{保持变量的总方差不变},同时具有最大方差,称为第一主成分,具有次大方差,称为第二主成分. 依次类推.

find application in face recognition and image compression, and is a common technique for finding patterns in data of high dimension.

\subsection{总体主成分的定义}
设$\vecteur{X}$ 为某实际问题涉及的n 个随机变量, 记$\mathrm{X} = \vecteur{X}^t$, 其协方差矩阵为
$$
\Sigma = (\sigma)_{n \times n} = E[(\mathrm{X} - E(\mathrm{X}))(\mathrm{X} - E(\mathrm{X}))^t]
$$
设$l_i = (l_{i1},l_{i2},\dots,l_{in})^t \eqspace (i=1,2,\dots,n)$, 考虑下列线性组合
$$
\left\{
  \begin{array}{ll}
	  Y_1 = l_1^t \mathrm{X} & = l_{11}X_1 + l_{12}X_2 + \cdots + l_{1n}X_n \\
	  Y_2 = l_2^t \mathrm{X} & = l_{21}X_1 + l_{22}X_2 + \cdots + l_{2n}X_n \\
		  \vdots\\
	  Y_n = l_n^t \mathrm{X} & = l_{n1}X_1 + l_{n2}X_2 + \cdots + l_{nn}X_n
  \end{array}
\right.
$$
有
$$
\begin{aligned}
E(Y_i)
& = E(l_i^t \mathrm{X}) \\
& = E(l_{i1}X_1 + l_{i2}X_2 + \cdots + l_{in}X_n) \\
& = l_{i}^t E(X)
\end{aligned}
$$
$$
\begin{aligned}
Cov(Y_i,Y_j)
& = E[(Y_i - E(Y_i))(Y_j - E(Y_j))^t] \\
& = E[(l_i^tX - l_i^tE(X_i))(l_j^tX - l_j^tE(X))^t] \\
& = E[l_i^t (X-E(X)) (X-E(X))^t l_j]\\
& = l_i^t E((X-E(X))(X-E(X))^t) l_j \\
& = l_i^t \Sigma l_j
\end{aligned}
$$
$$Var(Y_i) = Cov(Y_i,Y_i) = l_i^t \Sigma l_i$$

\subsection{求法}
$\Sigma$ 的特征值及相应的正交单位化向量分别为$\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_n \geq 0$ and $e_i,e_2,\cdots,e_n$, 则$X$ 的第$i$ 个主成分为
$$ Y_i = e_i^t \mathrm{X} = e_{i1}X_1 + e_{i2}X_2 + \cdots + e_{in}X_n, \eqspace i=1,2,\cdots,n $$
其中$e_i = (e_{i1}, e_{i2}, \cdots, e_{in})^t $\\
这时易见
$$
\left\{
	\begin{array}{l}
		Var(Y_i) = e_i^t \Sigma e_i = \lambda_i e_i^t e_i = \lambda_i, \eqspace i = 1,2,\cdots,n\\
		Cov(Y_i,Y_k) = e_i^t \Sigma e_k = \lambda_k e_i^t e_k = 0, \eqspace i \neq k
	\end{array}
\right.
$$

\subsection{性质}
\subsubsection{主成分的协方差及总方差}
令 $P = \vecteur{e}$, 则$P$ 为一正交矩阵, 记 $Y=\vecteur{Y}^t$ 为主成分向量, 则 $Y=P^t X$, 且
$$
Cov(Y) = Cov(P^t X) = P^t \Sigma P = Diag \vecteur{\lambda}
$$
由此得到, 主成分的总方差为
$$
\sum_{i=1}^n Var(Y_i) = \sum_{i=1}^n \lambda_i = tr(P^t \sigma P) = tr(\Sigma) = \sum_{i=1}^n Var(X_i)
$$

\subsubsection{主成分$Y_i$与$X_j$的相关系数}
由于$Y=P^t X$, 故 $X=PY$, 从而
$$
\left\{
  \begin{array}{l}
		  X_j = e_{1j}Y_1 + e_{2j}Y_2 + \cdots + e_{nj}Y_n \\
		  Cov(Y_i,X_j) = \lambda_i e_{ij}
  \end{array}
\right.
$$
由此可得$Y_i$与$X_j$ 的相关系数为
$$
\rho_{Y_i,X_j} = \frac{Cov(Y_i,X_j)}{\sqrt{Var(Y_i)} \sqrt{Var(X_j)}} = \frac{\lambda_i e_{ij}}{\sqrt{\lambda_i} \sqrt{\sigma_{jj}}} = \frac{\sqrt{\lambda_i}}{\sigma_{jj}} e_{ij}
$$

\subsubsection{标准化变量的主成分}
为了避免不同的物理量的不同量纲对计算的权重的影响, 需要normaliser.\\
令 $X_i^* = \dfrac{X_i - \mu_i}{\sqrt{\sigma_{ii}}}$, where $\mu_i = E(X_i), \sigma_{ii} = Var(X_i)$

\subsection{Sample(统计学的方式)}
\subsubsection{Variance(一维)}
$$
s = \dfrac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2
$$
Variance only operate on 1 dimension.
\textbf{Why are you using $n-1$ and not $n$?}\\
Well, the answer is a bit complicated, but in general, if your data set is a sample data set,
ie. you have taken a subset of the real-world (like surveying $500$ people about the election) then you must use $n-1$
because it turns out that this gives you an answer that is closer to the standard deviation that would result if you had used the entire population, than if you'd used $n$.
If, however, you are not calculating the standard deviation for a sample, but for an entire population, then you should divide by $n$ instead of $n-1$.\\
For further information, refer to \href{http://mathcentral.uregina.ca/RR/database/RR.09.95/weston2.html}{when $n$ or $n-1$ in computing the standard deviation}. 证明参见\href{http://en.wikipedia.org/wiki/Unbiased\_estimator#Sample\_variance}{wiki Sample Variance}

\subsubsection{Covariance Matrix of Random Vector}
设$X$为一列向量,
$$ \mathbf{X} = \begin{bmatrix}X_1 \\ \vdots \\ X_n \end{bmatrix} $$
The definition above is equivalent to the matrix equality

$$
\Sigma=\mathrm{E}
\left[
 \left(
 \textbf{X} - \mathrm{E}[\textbf{X}]
 \right)
 \left(
 \textbf{X} - \mathrm{E}[\textbf{X}]
 \right)^{\rm T}
\right]
$$

\subsubsection{Covariance Matrix of Sample}
设有$k$个variable, 然后为了估计它们的值, 我们进行了$n$次测量, 将这$n$次的测量结果记为矩阵$X$, 其中第$i,\ (i \in \{1,2, \ldots, n\})$行表示第$i$次测量的结果(这次测量的$k$个variable组成的一个行向量), $X$的第$j,\ (j \in \{1,2, \ldots, k\})$列表示第$j$个variable 的$n$次测量组成的一个列向量.\\
$$X = [X_1, X_2, \cdots, X_k]$$
则第$j$个variable 的测量均值: $\mean{X_j} = \dfrac{1}{n} \sum_{i= 1}^n X_{ij}$, 令
$$A = [X_1 - \mean{X_1}, X_2 - \mean{X_2}, \cdots, X_k - \mean{X_k}]$$
记$A_j = X_j - \mean{X_j}$\\
则矩阵$A$为对样本进行中心化之后的值.

Covariance matrix $\Sigma$
$$
\Sigma = \dfrac{1}{n - 1} A^T A
$$

$$
A^T A =
\begin{bmatrix}
A_1^T \\
A_2^T \\
\vdots \\
A_k^T \\
\end{bmatrix}
\begin{bmatrix}
A_1 & A_2& \cdots & A_k
\end{bmatrix}
=
\begin{bmatrix}
A_1^T A_1 & A_1^T A_2 & \cdots & A_1^T A_k \\
A_2^T A_1 & A_2^T A_2 & \cdots & A_2^T A_k \\
\vdots & \vdots & \ddots & \vdots \\
A_k^T A_1 & A_k^T A_2 & \cdots & A_k^T A_k \\
\end{bmatrix}
$$

\begin{example}
对$x,y$ 进行了$4$次测量, 结果如下表所示, 求$x,y$的相关性
\begin{table}[h]
\begin{tabular}{ll}
\hline
$x_i$ & $y_i$ \\
2.1   & 8     \\
2.5   & 12    \\ 
4.0   & 14    \\
3.6   & 10 \\
\end{tabular}
\end{table}

矩阵$X$为:
\begin{verbatim}
x =
    2.1000    8.0000
    2.5000   12.0000
    4.0000   14.0000
    3.6000   10.0000
\end{verbatim}
\begin{verbatim}
Octave : A = x - mean(x)
A =
  -0.95000  -3.00000
  -0.55000   1.00000
   0.95000   3.00000
   0.55000  -1.00000
\end{verbatim}
\begin{verbatim}
M =  A' * A / (4 - 1)
M =
   0.80333   1.53333
   1.53333   6.66667
\end{verbatim}
通过一般的方式(非矩阵方式)运算(参见\href{https://www0.gsb.columbia.edu/premba/analytical/s7/s7\_5.cfm}{$x,y$的相关性}), 我们得到$x,y$之间的covariance也是$1.53$.\\
Since the covariance is positive, the variables are positively related—they move together in the same direction.\\
同时, 我们可以求出$var(x)$为: \verb& sum(A(:,1) .^ 2) / 3 = 0.80333 & \\
$var(y)$为: \verb& sum(A(:,2) .^ 2) / 3 = 6.6667 & \\
这些值刚好就是协方差矩阵$M$的各个元素.\\
同时, 我们可以求出$x,y$的相关系数:
$$r_{xy} = \dfrac{Cov(x,y)}{\sqrt{var(x) \var(y)}} = \dfrac{M(1,2)}{\sqrt{M(1,2) M(2,2)}} = \dfrac{1.53}{\sqrt{0.80333 \times 6.6667}} = 0.66$$

\begin{verbatim}
octave: [u,s,v] = svd(M) %% M = u s v^T
u =
   0.23862   0.97111
   0.97111  -0.23862

s =
   7.04344         0
         0   0.42656

v =
   0.23862   0.97111
   0.97111  -0.23862
\end{verbatim}
通过矩阵$s$的两个特征值, 我们可以看到$\lambda_1 \gg \lambda_2$, 根据PCA, 我们可以对$x,y$进行降维, 第一主轴的方向向量为$u_1 = (0.23862, 0.97111)^T$. 用数据对这个方向进行验证:
$0.23862 / 0.97111 = 0.24572$

\begin{verbatim}
octave: x(:,1)./x(:,2)
ans =
   0.26250
   0.20833
   0.28571
   0.36000

octave: mean(x(:,1)./x(:,2))
ans =  0.27914
\end{verbatim}
各个数据的比值与主轴的方向还是挺接近的.
%% \begin{verbatim}
%% \end{verbatim}
\end{example}

更一般地情况:\\
If $\mathbf{M}_{\mathbf{X}}$ and $\mathbf{M}_{\mathbf{Y}}$ are centred data matrices of dimension $n$-by-$p$ and $n$-by-$q$ respectively, i.e. with $n$ rows of observations of $p$ and $q$ columns of variables, from which the \textbf{column means have been subtracted}, then, if the column means were estimated from the data, sample covariance matrices $\mathbf{Q}_{\mathbf{X}}$ and $\mathbf{Q}_{\mathbf{XY}}$ can be defined to be
$$
\mathbf{Q}_{\mathbf{X}} = \frac{1}{n-1} \mathbf{M}_{\mathbf{X}}^T \mathbf{M}_{\mathbf{X}}, \qquad \mathbf{Q}_{\mathbf{XY}} = \frac{1}{n-1} \mathbf{M}_{\mathbf{X}}^T \mathbf{M}_{\mathbf{Y}}
$$
or, if the column means were known a-priori,
$$
\mathbf{Q}_{\mathbf{X}} = \frac{1}{n} \mathbf{M}_{\mathbf{X}}^T \mathbf{M}_{\mathbf{X}}, \qquad \mathbf{Q}_{\mathbf{XY}} = \frac{1}{n} \mathbf{M}_{\mathbf{X}}^T \mathbf{M}_{\mathbf{Y}}
$$
These empirical sample covariance matrices are the most straightforward and most often used estimators for the correlation matrices, but other estimators also exist, including regularised or shrinkage estimators, which may have better properties.

\subsubsection{PCA 的求解过程}
\begin{enumerate}
\item Get some data
\item Subtract the mean
\item Calculate the covariance matrix
\item Calculate the unit eigenvectors and eigenvalues of the covariance matrix
\item Choosing components and forming a feature vector
\item Deriving the new data set
\end{enumerate}
\end{document}

