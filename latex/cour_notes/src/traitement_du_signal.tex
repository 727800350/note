% !Mode:: "TeX:UTF-8"
\documentclass{article}
\input{../../public/package}
\input{../../public/article}
\begin{document}
\title{Traitement du signal}
\maketitle
\tableofcontents
\newpage

\section{Introduction}
模拟信号: 连续时间连续幅度变化

数字信号处理系统的三种方式: 软件实现; 硬件实现; 软硬件结合(数字信号处理器Digital Signal Processor,DSP)

数字信号处理系统由耗电的有源器件(晶体管)构成; 而模拟处理系统使用电阻, 电容, 电感等无源器件, 所以数字处理系统的功耗比较大.

音乐信号的处理:  
如使用压缩器和扩张器来压缩或扩张音乐信号的幅度范围;
使用均衡器和滤波器改变音乐信号的频率分布

\section{\'Echantillonnage}
采样定理,又称香农采样定理,奈奎斯特采样定理,是信息论,特别是通讯与信号处理学科中的一个重要基本结论

如果信号是带限的,并且采样频率大于信号带宽的2倍,那么,原来的连续信号可以从采样样本中完全重建出来.

\textbf{奈奎斯特频率(Nyquist频率)}是离散信号系统采样频率的一半.

只要离散系统的奈奎斯特频率高于被采样信号的最高频率或带宽,就可以避免混叠现象.

如果不能满足上述采样条件,采样后信号的频率就会重叠,即高于采样频率一半的频率成分将被重建成低于采样频率一半的信号.这种频谱的重叠导致的失真称为混叠,而重建出来的信号称为原信号的混叠替身,因为这两个信号有同样的样本值.

Le théorème d'échantillonnage énonce que l'échantillonnage d'un signal, c'est-à-dire sa représentation sous une forme discrète, par une liste de valeurs prélevées régulièrement dans ce signal, exige une fréquence d'échantillonnage supérieure au double de l'écart entre les fréquences minimale et maximale qu'il contient.

Dans le cas le plus courant, la fréquence minimale du signal est petite par rapport à sa fréquence maximale et le théorème affirme plus simplement :

La représentation discrète d'un signal par des échantillons régulièrement espacés exige une fréquence d'échantillonnage supérieure au double de la fréquence maximale présente dans ce signal.

En général, on échantillonne dans l'intervalle compris entre 0 et la fréquence de Nyquist, c'est-à-dire la moitié de la fréquence d'échantillonnage.

\section{Ergodique 遍历}
L'hypothèse ergodique, ou hypothèse d'ergodicité, est une hypothèse fondamentale de la physique statistique. Elle fut formulée initialement par Ludwig Boltzmann

Elle s'appliquait alors aux systèmes composés d'un très grand nombre de particules, et affirmait qu'à l'équilibre, la valeur moyenne d'une grandeur calculée de manière statistique est égale à la moyenne d'un très grand nombre de mesures prises dans le temps.\\
La première valeur est celle que permet de calculer la physique statistique, la seconde est proche de ce qu'on peut expérimentalement mesurer.\\
L'hypothèse ergodique est donc fondamentale pour un bon rapprochement entre la théorie et l'expérience.

L'hypothèse d'ergodicité intervient également en \textbf{traitement du signal}, où elle consiste à admettre que \textbf{l'évolution d'un signal aléatoire au cours du temps apporte la même information qu'un ensemble de réalisations}.

Elle est importante dans l'étude des chaines de Markov, les processus stationnaires et pour l'apprentissage numérique.

\textbf{Approche intuitive de l'hypothèse ergodique}\\
D'une facon intuitive, reprendre l'exemple d'un gaz, les milliards de particules qui le constituent peuvent être considérées comme des copies les unes des autres ayant toutes le même comportement aléatoire. 
Elles prennent chacune des valeurs aléatoires, probablement différentes, de position et de vitesse à un instant donnée. \\
La vitesse moyenne des particules peut se calculer en \textbf{sommant les vitesses de toutes les particules à un instant donné}. \\
Cependant, on peut calculer également une moyenne en \textbf{considérant une seule particule} mais en mesurant ses vitesses \textbf{à différents instants}.\\
L'hypothèse d'ergodicité revient à dire que \textbf{les deux méthodes sont équivalentes}.

On peut également penser à une forêt d'une seule espèce et s'intéresser à la croissance d'un arbre en fonction du temps : l'hypothèse ergodique revient à considérer qu'il est similaire d'observer la forêt à un instant donné qu'un arbre tout au long de sa vie pour en conna?tre l'évolution (par exemple relever le diamètre du tronc en fonction du temps ou mesurer tous les diamètres de la forêt et le reporter en fonction de l'age de l'arbre).

\bigskip
Un \textbf{processus ergodique} est un processus stochastique pour lequel les statistiques peuvent être approchées par l'étude d'une seule réalisation suffisamment longue.

\bigskip
\textbf{Lien avec la stationnarité}\\
Un signal peut être:\\
stationnaire mais non ergodique.\\
ergodique mais non stationnaire; par exemple le signal $Z(x; \omega)=A(\omega)$ constant pour chaque réalisation.

\section{Representation in Terms of Basis Functions}
下面的section的参考资料:
\href{http://www.amazon.com/Continuous-Discrete-Signal-System-Analysis/dp/0030510198}{Continuous and Discrete Signal and System Analysis}

The set of basis functions: $ \phi_{-N}(t), \ldots, \phi_{-2}(t), \phi_{-1}(t), \phi_0(t), \phi_1(t), \phi_2(t), \ldots, \phi_N(t)$, Where $N$ may be infinity in some cases.\\
The linear combination of these as:
\begin{equation}
x(t) = \sum_{n = -N}^N a_n \phi_n(t)
\label{eq.base.combination}
\end{equation}

One property that is desired for a set of basis functions is known as \textbf{finality of coefficients}.\\
It allows one to determine any given coefficient without needing to know any other coefficient. 
Stated another way, more terms can be added to the representation(to obtain greater accuracy, for example) without making any changes in the earlier coefficients.\\
To achive finality of coefficients, it is necessary that the basis functions be \textbf{orthogonal over the time interval} 
for which the representation is to be valid.

The condition for orthogonality of basis functions requires that for all k,
$$
\int_{t_1}^{t_2} \phi_n(t) \phi_k^{*}(t)
=
\begin{cases}
	0 & k \neq n\\
	\lambda_k & k = n
\end{cases}
$$
where $\phi_k^{*}(t)$ is the complex conjugate of $\phi_k(t)$ and $\lambda_k$ is real. For real basis functions this condition becomes:
$$
\int_{t_1}^{t_2} \phi_n(t) \phi_k(t)
=
\begin{cases}
	0 & k \neq n\\
	\lambda_k & k = n
\end{cases}
$$
If $\lambda_k = 1$ for all $k$, the basis functions are said to be \textbf{orthonormal}.

The limits of integration in the last two equations can define either a finite interval or an infinite(semi-infinite) interval, 
depending upon the nature of problem.

In order to demonstrate how the coefficients can be determined, multiply both sides of equation \eqref{eq.base.combination} by $\phi_j^{*}(t)$ , for any $j$, and integrate over the specified interval. This gives
\begin{equation}
\int_{t_1}^{t_2} \phi_j^{*}(t)x(t)dt 
= \int_{t_1}^{t_2} \phi_j^{*}(t) [\sum_{n = -N}^N a_n \phi_n(t)] dt 
= \sum_{n = -N}^N a_n \int_{t_1}^{t_2} \phi_j^{*}(t) \phi_n(t) dt 
\end{equation}

From the orthogonality condition, equation \lasteq may be written as
$$ \int_{t_1}^{t_2} \phi_j^{*}(t) x(t) dt = a_j \lambda $$
Since all the terms on the right side of equation \lasteq will be zero except for $n = j$. Thus, the coefficient $a_j$ may be expressed quite generally as
\begin{equation}
a_j = \frac{1}{\lambda_j} \int_{t_1}^{t_2} \phi_j^*(t) x(t) dt
\end{equation}

When the basis functions are complex, eg., a complex Fourier series representation, it is very likely that the coefficients $a_j$ will be complex too.

The enery or average power of a signal:
\begin{equation}
E 
= \int_{t_1}^{t_2}x^2(t)dt
= \int_{t_1}^{t_2}x(t) \sum_{n = -N}^N a_n \phi_n(t) dt
= \sum_{n = -N}^N a_n \int_{t_1}^{t_2}x(t) \phi_n(t) dt
\end{equation}
Now it is seen that, assuming $x(t)$ is real, the integral in equation \lasteq is $\lambda_n$ times the complex conjugate of $a_n$. Therefore,
\begin{equation}
E
= \sum_{n = -N}^N a_n \lambda_n a_n^* = \sum_{n = -N}^N \lambda_n \norm{a_n}^2
\end{equation}

\subsection{Energy}
Since $\lambda_n$ is the energy in the nth basis function, 
each term of the summation in \lasteq is simply the energy associated with the nth component of the representation. 
Thus, \lasteq states that \textbf{the energy of singal is the sum of the energies of its individual orthogonal components, regardless of what form they may have}. \\
This is one form of a quite general theorm that is usually referred to as \textit{Parseval}'s theorem.

In almost all cases, the value of $N$ in equation \eqref{eq.base.combination} required for an exact representation will be infinity,
but the values of $a_n$ tend to be smaller as $n$ becomes large. 

\subsection{Approximation}
Since it is not possible to use an infinite number of terms in any pratical situation, 
the series must be terminated after some finite number of terms, and the resulting expression is an approximation to $x(t)$. 

Thus the approximation $\hat{x}(t)$ may be expressed as
\begin{equation}
\hat{x}(t) = \sum_{n = -M}^M a_n \phi_n(t)
\end{equation}

The integral squared error:
$$
I = \int_{t_1}^{t_2} \norm{x(t) - \hat{x}(t)}^2 dt
$$
经过一系列的运算, 我们可以证明当$I$ 取最小值时, $\hat{a}_n = a_n$.\\
From this result it may be conclued that the previously defined coefficients $a_n$ are also the best ones from the standpoint of minimizing the approximation error when only a finite number of terms is used.

\section{The implulse function}
delta function

It should be emphasized that the factor multiplying an impulse is really designing the \textit{area} of the impulse and is not just scaling its magnitude.
Thus, $A\delta(t-a)$ is an impulse with an area of $A$ located at $t=0$

The delta function is defined to be a function satisfies the following conditions:
\begin{enumerate}
\item $\delta(t - t_0) = 0 \eqspace t \neq t_0$
\item $\int_{t_1}^{t_2} \delta(t - t_0)dt =1 \eqspace t_1 < t_0 < t_2$
\item $\int_{- \infty}^{+ \infty} f(t) \delta(t - t_0)dt = f(t_0) \eqspace f(t) \text{continuous at }t_0$
\end{enumerate}

\bigskip
Some other properties:\\
Time scaling:
$$ \delta(bt - t_0) = \frac{1}{\norm{b}} \delta(t - \frac{t_0}{b}) $$

Integral of product of delta function:
$$ \int_{t_1}^{t_2} \delta(\lambda - t) \delta(\lambda - t_0)d \lambda = \delta(t - t_0) \eqspace t_1 < t_0 < t_2 $$

\section{Fourier Transform}
Suppose $x(t)$ a periodic function with period $T$
$$ x(t) = \sum_{n = - \infty}^{\infty} \alpha_n e^{jn\omega_0 t} $$

The Fourier transform then becomes:
$$
\begin{aligned}
		X(\omega) & = \mathcal{F}\{\sum_{n = - \infty}^{\infty} \alpha_n e^{jn\omega_0 t}\} \\
				  & =  \sum_{n = - \infty}^{\infty} \alpha_n \mathcal{F}\{e^{jn\omega_0 t}\} \\
				  & =  2\pi \sum_{n = - \infty}^{\infty} \alpha_n \delta(\omega - n \omega_0)
\end{aligned}
$$

The constants $\alpha_n$ can be expressed in terms of the Fourier transform of $x_T(t)$, the waveform over one period, as fllows:
$$
\begin{aligned}
		\alpha_n & = \frac{1}{T} \int_{ - T/2}^{T/2} x(t) e^{-jn\omega_0 t}dt \\
			     & = \frac{1}{T} \int_{ - T/2}^{T/2} x_T(t) e^{-jn\omega_0 t}dt \\
  				   & = \frac{1}{T} X_T(n\omega_0)
\end{aligned}
$$

Therefore, 
$$ X(\omega) = \omega_0 \sum_{n = - \infty}^{\infty} X_T(n\omega_0)\delta(\omega - n \omega_0) $$
$$ x(t) \Leftrightarrow \frac{2\pi}{T} \sum_{n = - \infty}^{\infty} X_T(\frac{2\pi n}{T})\delta(\omega - \frac{2\pi n}{T}) $$

The Fourier transform is thus seen to be a series of impulses at the harmonics of the repetition period with strengths determined by the shape of the waveform in one period.

\subsection{Unit Impulse Train}
\href{http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Dirac\_comb.svg/300px-Dirac\_comb.svg.png}{Figure of Unit Impulse Train}

$$x(t) = \sum_{n = - \infty}^{\infty} \delta(t - nT)$$
写成Fourier Series 的形式:
$$x(t) = \sum_{n = - \infty}^{\infty} \alpha_n e^{jn\omega_0 t} \eqspace \omega_0 = \frac{2\pi}{T}$$

$$
\begin{aligned}
		\alpha_n & = \frac{1}{T} \int_{ - T/2}^{T/2} x(t) e^{-jn\omega_0 t}dt \\
				& = \frac{1}{T} \int_{ - T/2}^{T/2} (\sum_{n = - \infty}^{\infty} \delta(t - nT)) e^{-jn\omega_0 t}dt \\
				& = \sum_{n=-\infty}^{\infty} \frac{1}{T} \int_{ - T/2}^{T/2} \delta(t - nT) e^{-jn\omega_0 t}dt \\
			 	&\text{As nT in [-T/2, T/2], n can only equal to 0}\\
				 &= \frac{1}{T} \int_{-T/2}^{T/2} \delta(t) \times 1 dt \\
				 & = \frac{1}{T}
\end{aligned}
$$

Therefore, $x(t)$ can be written as
$$ x(t) = \frac{1}{T} \sum_{n = - \infty}^{\infty} e^{jn\omega_0 t} $$
Taking the Fourier transform gives:
\begin{equation}
\begin{aligned}
X(\omega)
& = \frac{1}{T} \sum_{n = -\infty}^{\infty} \mathcal{F}\{ e^{jn\omega_0 t} \} \\
& = \frac{2\pi}{T} \sum_{n = -\infty}^{\infty} \delta(\omega - n\omega_0) \\
\sum_{n = - \infty}^{\infty} \delta(t - nT)
& \Leftrightarrow
\frac{2\pi}{T} \sum_{n = -\infty}^{\infty} \delta(\omega - n\omega_0) \\
\end{aligned}
\end{equation}

In terms of frequency $f$, \lasteq can be written as
$$
\sum_{n = - \infty}^{\infty} \delta(t - nT)
\Leftrightarrow
\frac{1}{T} \sum_{n = -\infty}^{\infty} \delta(f - \dfrac{n}{T}) \\
$$

Thus, it is seen that an impulse train in the time domaine has as its Fourier transform an impulse train in the frequency domain.

Unit impulse train 在时域(a)与频域(b)上的对比:
\href{http://i.imgbox.com/GHbA7Fbm.jpg}{The Unit impulse train}
\end{document}
