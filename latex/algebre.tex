\documentclass{article}
    \usepackage[french]{babel}
    \usepackage{ctex}
    \usepackage{amsmath, amsthm, amssymb}
   \usepackage[top=2.54cm, bottom=2.54cm, left=3.18cm, right=3.18cm]{geometry} % ms word
   % \usepackage[top=0.2cm, bottom=0.2cm, left=0cm, right=0cm,paperwidth=9cm,paperheight=11.7cm]{geometry} % kindle

\begin{document}
\title{Mes notes d'Alg\`ebre}
\maketitle
\tableofcontents
\newpage

%¹ØÓÚ¶¨Òå¶¨ÀíµÈµÄ±àºÅ
\newtheorem{definition}{D\'efintion} %ÕûÆªÎÄÕÂµÄÈ«¾Ö±àºÅ
\newtheorem*{thmwn}{Thm} %without numbers
\newtheorem{theorem}{Th\'eor\`eme}[section]%´ÓÊôÓÚsection±àºÅ
\newtheorem{lemma}[theorem]{Lemme}%theoremÍ³Ò»±àºÅ
\newtheorem{proposition}{Proposition}[section]%´ÓÊôÓÚsection±àºÅ
\newtheorem{corollary}{Corollary}[theorem]%´ÓÊôÓÚtheorem±àºÅ
\newtheorem{example}{Example}%ÕûÆªÎÄÕÂµÄÈ«¾Ö±àºÅ
\newtheorem*{attention}{Attention}
\newtheorem*{note}{Note}
\newtheorem{question}{Question}[section]


%############################################################## Algebre 1 µÚÒ»ÕÂ #########################################################################
\section{Logique et ensembles}
La relation $1+1 \neq 2$ est fausse,la double n\'egation est la relation $1+1=2$. Elle est vraie.
\newline
disjonction »ò,ÎöÈ¡ \newline
conjonction ºÍ,ºÏÈ¡ \newline
axiome ¹«Àí \newline
conjecture ²ÂÏë\newline
le quantificateur existentiel $\exists$ \newline
le quantificateur universel $\forall$ \newline
\\
Un th\'eor\`eme est simplement une phrase vraie. \newline

%µ±ÇÒ½öµ±
P si et seulement si Q: \newline
P si Q, c'est si Q, alors P.\quad $Q \Rightarrow P$ \newline
P seulement si Q: c'est si P, alors Q. \quad $P \Rightarrow Q$
\\
$P \Rightarrow (Q \Rightarrow R)\Leftrightarrow (P \Rightarrow Q)\rightarrow (P \Rightarrow R)$ \newline
La diff\'erence sym\'etrique de deux ensembles $E,F$. C'est l'ensemble des \'el\'ements qui appartient \^a exactement un des ensembles $E,F$. On le note $ E \Delta F $.
\newline
$
E \Delta F=\{x|x\in E ~\mathrm{et} ~x \not \in F\}\cup\{x|x\in F et x \not \in E\}=(E-F)\cup(F-E)
$

Une application est la m\^eme chose qu'une famille \`a valeurs dans $F$ index\'ee par $E$. Si on note ${\cal F}(E,F)$ l'ensemble de toutes les applications de $E$ vers $F$, on a bien s\^ur
$$
{\cal F}(E,F)=F^E
$$

Si $E$ , $F$ sont finis, alors ${\cal F}(E,F)$ et $F^E$ sont finis, et
$$
|{\cal F}(E,F)|=|F^E|=|F|^|E|
$$

%############################################################## Algebre 1 µÚ¶şÕÂ #########################################################################
\section{Groupes. Anneaux. Corps}
$$
\begin{array}{l|llll}
groupe & ajouter & soustraire &&\\
\hline
anneau & ajouter & soustraire & multiplication & \\
\hline
corps & ajouter & soustraire & multiplication & division
\end{array}
$$


Si A est un anneau, on appelle  {\bf groupe des inversibles de} $A$ l'ensemble des \'el\'ements inversibles de $A$, muni de la deuxi\`eme op\'eration de $A$. On note ce groupe $A^o$

%############################################################## Algebre 1 µÚÈıÕÂ #########################################################################
\section{Espace vectoriel}
\begin{theorem}
  On a une d\'ecomposition en somme directe de deux sous-espaces $ V = W_1 \bigoplus W_2$  si et seulment si
  $$
    \begin{cases}
    V=W_1+W_2 \\
    W_1\cap W_2=\{0\}
    \end{cases}
  $$
\end{theorem}
\begin{attention}
  Si le nombre de sous-espaces est $n\geqslant 3$, on peut plus dire que
  $$
    \begin{cases}
    V=W_1+\dots+W_n \\
    \forall i \neq j,W_i\cap W_j=\{0\}
    \end{cases}
  $$
  implique $ V = W_1 \bigoplus \dots \bigoplus W_n$
\end{attention}

\begin{theorem}
  Soit $f:V \rightarrow W$ une application lin\'eaire. Soit $w \in W$ un vecteur donn\'e. On note
  $$
  S=\{x \in V|f(x)=w\}
  $$
  Alors $S$ est soit l'ensemble vide, soit un ensemble de la forme $\{x_0+v|v \in ker f\}$, o\`u $x_0$ est une solution particuli\`ere de l'\'equation $f(x_0)=w$.
\end{theorem}
\begin{note}
  ÏëÒ»Ïë½âÏßĞÔÎ¢·Ö·½³ÌµÄÊ±ºò,ÎÒÃÇÒ²ÓÃµ½ÁËÕâÖÖË¼Ïë,ÏÈÕÒÍ¨½â,È»ºóÔÙÕÒÒ»¸öÌØ½â,×éºÏÔÚÒ»Æğ,¾Í¹¹³ÉÁËÎ¢·Ö·½³ÌµÄÍêÕû½â.
\end{note}

\begin{theorem}

1. Soit $V$ un espace vectoriel de dimension finie $n$ sur le corps commutatif $K$. \\
Alors il existe un isomorphisme de $K^n$ vers $V$.
\medskip

2. S'il existe un isomorphisme de $K^n$ vers $V$, alors $V$ est de dimension $n$.

\medskip


3. Soient $V$ et $W$ deux espaces vectoriels isomorphes (il existe un isomorphisme de $V$ vers $W$ et un isomorphisme de $W$ vers $V$). On suppose que l'un des deux espaces est de dimension finie. Alors $V$ et $W$ ont la m\^eme dimension.

\medskip

4. Si $V,W$ sont de dimension finie, et $\dim V = \dim W$, alors $V$ et $W$ sont isomorphes.

\end{theorem}


\bigskip

\begin{proof}

1. Soit $(e_1,\dots, e_n)$ une base de $V$. On d\'efinit l'application $u : K^n \to V$ comme suit:
$$
u(\lambda_1,\dots ,\lambda_n) = \sum_{i=1}^n \lambda_i \cdot e_i
$$
Il est \'evident que $u$ est une application lin\'eaire. Comme $(e_i)$ est une famille g\'en\'eratrice de $V$, il est
\'egalement clair que $u$ est surjective. Reste \`a montrer l'injectivit\'e de $u$.

\medskip

Par lin\'earit\'e de $u$, il suffit de montrer que si $u(\lambda_1,\dots ,\lambda_n) = 0_V$, alors
tous les $\lambda_i$ sont nuls. Or cela est vrai, puisque la famille $(e_i)$ est libre. Comme $u$ est une application lin\'eaire surjective et injective, il s'agit d'un isomorphisme d'espaces vectoriels.

\medskip

2. Soit $u: K^n \to V$ un isomorphisme. On consid\`ere une base $(e_1,\dots ,e_n)$ de $K^n$ (par exemple la
base canonique). On regarde maintenant la famille
$$
(f_1,\dots ,f_n) = (u(e_1), \dots, u(e_n))
$$
Pour montrer que $V$ est de dimension $n$, il suffit de se convaincre que la famille $(f_i)$ est une base de $V$.
Montrons d'abord qu'elle est libre.

\medskip

Si $\sum_{i=1}^n \lambda_i \cdot f_i = \sum_{i=1}^n \lambda_i \cdot u(e_i) =0_V$, alors par lin\'earit\'e de $u$ on aura
$$
u\left( \sum_{i=1}^n \lambda_i \cdot e_i \right) = 0_V.
$$
Or $u$ est un isomorphisme, donc en particulier c'est une injection. Et comme $u(0)=0$, on doit avoir
$$
 \sum_{i=1}^n \lambda_i \cdot e_i  = 0
 $$
 Mais la famille $(e_i)$ est en particulier une famille libre, donc tous les $\lambda_i$ sont nuls.
 Nous avons prouvé que la famille $(f_i)$ est libre.

 \medskip

 Montrons maintenant que la famille $(f_i)$ est g\'en\'eratrice. Soit $v$ vecteur quelconque de $V$. Puisque
 $u$ est une surjection, il existe un vecteur $t \in K^n$ avec $u(t)=v$. Comme $(e_i)$ est une famille g\'en\'eratrice
de $K^n$, il existe des scalaires $(\lambda_1, \dots, \lambda_n)$ avec
$$
t = \sum_{i=1}^n \lambda_i \cdot e_i
$$
Mais alors
$$
v= u(t) = u\left(  \sum_{i=1}^n \lambda_i \cdot e_i \right) = \sum_{i=1}^n \lambda_i \cdot u(e_i)
= \sum_{i=1}^n \lambda_i f_i
$$
Nous avons montr\'e que $(f_i)$ est bien une famille g\'en\'eratrice. Cette famille est bien une base de $V$.

\bigskip

3. C'est une cons\'equence imm\'ediate de 1. et 2.

\bigskip

4. Soit $n$ la dimension commune de $V$ et $W$. Par 1. les deux espaces vectoriels sont alors isomorphes
\`a l'espace vectoriel $K^n$. Puisque la composition de deux isomorphismes est encore un isomorphisme, on en d\'eduit
que $V$ et $W$ sont isomorphes.

\end{proof}

%############################################################## Algebre 2 µÚÒ»ÕÂ #########################################################################
\section{Matrices}
\begin{definition}
  Soient $V,W$ deux espaces vectoriels sur un corps communitatif $K$ avec dim$V=n$,dim$W=p$,\newline
  soit $e=(e_1,\ldots,e_n)$ une base de $V$, et $f=(f_1,\ldots,f_n)$ une base de $W$. \newline
  On appelle {\bf matrice associ\'ee \`a $u$ dans les bases} $e,f$ et on note ${\cal M}_f^e(u)$ la matrice $p \times n$ d\'efinie par la r\`egle:
  $\forall j \in [[1,n]], u(e_j)= \sum_{i=1}^p ({\cal M}_f^e(u))_{ij} \cdot f_i $. Autrement dit,
  $\forall i \in [[1,p]],\forall j \in [[1,n]]$, le scalaire $({\cal M}_f^e(u))_{ij}$ est la i-\`eme coordonn\'ee du vecteur $u(e_j) \in W $ dans la base $f$.
\end{definition}
\begin{note}
  Les {\bf coordonn\'ees de $u(e_j)$ dans la base $f$} sont les coeficients qui se trouvent dans {\bf la colonne num\'er\'e $j$ de la matrice}
  ${\cal M}_f^e(u)$.
\end{note}

\begin{theorem}
  $ \forall v \in V, {\cal C}_f(u(v))= {\cal M}_f^e(u)\cdot {\cal C}_e(v) $
\end{theorem}

\begin{note}
 $ {\cal M}_f^e(u)\cdot {\cal P}_{e\rightarrow e'}= {\cal M}_f^e(u)\cdot {\cal M}_e^{e'}(id_V)={\cal M}_f^{e'}(u)$
\end{note}

\subsection{¾ØÕóµÄÔËËã}
\subsubsection{ÁĞÏòÁ¿×é}
Èô$A$µÄÁĞÏòÁ¿×éÎª$\alpha_1,\ldots,\alpha_n$,ÄÇÃ´ÎÒÃÇ¿ÉÒÔ°Ñ$A$Ğ´³É:$A=(\alpha_1,\ldots,\alpha_n)$ \newline
Éè$A=(a_{ij})_{s\times n},B=(b_{ij})_{n\times m},A$ µÄÁĞÏòÁ¿×éÎª$\alpha_1,\ldots,\alpha_n$. \newline
$AB$µÄµÚ$j\in [[1,m]]$ÁĞÎª: \newline
$$
\begin{bmatrix}
  a_{11}b_{1j}+a_{12}b_{2j}+\dots+a_{1n}b_{nj}  \\
  a_{21}b_{1j}+a_{22}b_{2j}+\dots+a_{2n}b_{nj}  \\
  \vdots \\
  a_{s1}b_{1j}+a_{s2}b_{2j}+\dots+a_{sn}b_{nj}
\end{bmatrix}
\\
=
b_{1j}\alpha_1+b_{2j}\alpha_2+\dots+b_{nj}\alpha_n
$$
ÓÚÊÇ
$$
AB=(\alpha_1,\ldots,\alpha_n)
\begin{bmatrix}
  b_{11} & b_{12} & \dots & b_{1m}  \\
  b_{21} & b_{22} & \dots & b_{2m}  \\
  \vdots & \vdots & \vdots &\vdots \\
  b_{n1} & b_{n2} & \dots & b_{nm}
\end{bmatrix}
%=(b_{11}\alpha_1+b_{21}\alpha_2+\dots+b_{n1}\alpha_n,b_{12}\alpha_1+b_{22}\alpha_2+\dots+b_{n2}\alpha_n,\ldots,b_{1m}\alpha_1+b_{2m}\alpha_2+\dots+b_{nm}\alpha_n,)
%ÉÏÃæµÄÕâÒ»ĞĞÏÔÊ¾²»È«,ËùÒÔÅ²µ½ÏÂÃæÁË
$$
$=(b_{11}\alpha_1+b_{21}\alpha_2+\dots+b_{n1}\alpha_n,b_{12}\alpha_1+b_{22}\alpha_2+\dots+b_{n2}\alpha_n,\ldots,b_{1m}\alpha_1+b_{2m}\alpha_2+\dots+b_{nm}\alpha_n,)$
\begin{note}
  B¶ÔA½øĞĞÁĞ±ä»» \newline
  A³ËÒÔB¿ÉÒÔ¿´×ö°ÑAµÄÁĞÏòÁ¿×é·Ö±ğÓëBµÄÃ¿Ò»ÁĞµÄ¶ÔÓ¦ÔªËØµÄ³É¼¨Ö®ºÍ×÷ÎªABµÄÏàÓ¦µÄÁĞÏòÁ¿.
\end{note}

\subsubsection{ĞĞÏòÁ¿×é}
ÉèBµÄĞĞÏòÁ¿×éÎª$r_1,r_2,\ldots,r_n$,Ôò
$$
AB=
\begin{bmatrix}
  a_{11} & a_{12} & \dots & a_{1n}  \\
  a_{21} & a_{22} & \dots & a_{2n}  \\
  \vdots & \vdots & \vdots &\vdots \\
  a_{s1} & a_{s2} & \dots & a_{sn}
\end{bmatrix}
\cdot
\begin{bmatrix}
  r_1 \\
  r_2 \\
  \vdots \\
  r_n
\end{bmatrix}
=
\begin{bmatrix}
  a_{11}r_1 + a_{12}r_2 + \dots + a_{1n}r_n  \\
  a_{21}r_1 + a_{22}r_2 + \dots + a_{2n}r_n   \\
  \vdots \\
  a_{s1}r_1 + a_{s2}r_2 + \dots + a_{sn}r_n
\end{bmatrix}
$$
$A\times B$¿ÉÒÔ¿´×ö°ÑAµÄÃ¿Ò»ĞĞÔªËØÓëBµÄĞĞÏòÁ¿×éµÄ¶ÔÓ¦µÄĞĞÏòÁ¿µÄ³É¼¨×÷ÎªABÏàÓ¦µÄĞĞÏòÁ¿.

\begin{question}
  ÉèAÎªÊıÓòKÉÏ$s \times n$µÄ¾ØÕó,Ö¤Ã÷:Èç¹û¶ÔÓÚ$K^n$ÖĞÈÎÒ»ÁĞÏòÁ¿$\eta$,¶¼ÓĞ$A\eta=0$,ÄÇÃ´$A=0$
\end{question}
\begin{proof}
  Éè$u:x \in K^n \rightarrow Ax \in K^s$,ÇÒ$A=(\alpha_1,\ldots,\alpha_n)$ \newline
  ÎÒÃÇÇó³öuÔÚbase canoniqueÏÂµÄ¾ØÕó \newline
  $$
  u(\begin{bmatrix}
    1 \\
    0\\
    \vdots \\
    0
  \end{bmatrix})
  =A \cdot
  \begin{bmatrix}
    1 \\
    0\\
    \vdots \\
    0
  \end{bmatrix}
  =\alpha_1=0
  $$
  Í¬Àí,ÎÒÃÇ¿ÉÒÔµÃµ½$\alpha_2=\dots=\alpha_n=0$,ËùÒÔ$A=0$ \newline
  »òÕß,ÎÒÃÇ¿ÉÒÔÖ±½ÓĞ´
  $$
  A=AI=A(\epsilon_1,\ldots,\epsilon_n)=(A\epsilon_1,\dots,A\epsilon_n)=(0,\ldots,0)=0
  $$
\end{proof}

\subsection{ÌØÊâ¾ØÕó}
\subsubsection{¶Ô½Ç¾ØÕó}
la matrice diagonale,$diag(d_1,\ldots,d_n)$ \newline
ÓÃÒ»¸ö¶Ô½Ç¾ØÕó{\bf ×ó(ÓÒ) }³ËÒ»¸ö¾ØÕóA,¾ÍÏàµ±ÓÚÓÃ¶Ô½Ç¾ØÕóµÄÖ÷¶Ô½ÇÔªËØ·Ö±ğÈ¥³ËAÏàÓ¦µÄ{\bf ĞĞ(ÁĞ)}.
%¶Ô½Ç¾ØÕó×ó³ËÒ»¸ö¾ØÕó
$$
\begin{bmatrix}
  d_1 & 0  & 0 & \cdots & 0 \\
  0   & d_2 & 0 & \cdots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & 0 & \cdots & d_s
\end{bmatrix}
\times
\begin{bmatrix}
  r_1  \\
  r_2 \\
  \vdots \\
  r_s \\
\end{bmatrix}
=
\begin{bmatrix}
  d_1 r_1  \\
  d_2 r_2 \\
  \vdots \\
  d_s r_s \\
\end{bmatrix}
$$

%¶Ô½Ç¾ØÕóÓÒ³ËÒ»¸ö¾ØÕó
$$
(\alpha_1,\ldots,\alpha_n)
\times
\begin{bmatrix}
  d_1 & 0  & 0 & \cdots & 0 \\
  0   & d_2 & 0 & \cdots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & 0 & \cdots & d_n
\end{bmatrix}
=
\begin{bmatrix}
  d_1 \alpha_1 & d_2 \alpha_2 & \dots & d_n \alpha_n \\
\end{bmatrix}
$$

ÌØ±ğµÄ,Á½¸ön¼¶¶Ô½Ç¾ØÕóµÄ³Ë»ı»¹ÊÇn¼¶¶Ô½Ç¾ØÕó,²¢ÇÒÊÇ°ÑÏàÓ¦µÄÖ÷¶Ô½ÇÔªÏà³Ë

\subsubsection{Èı½Ç¾ØÕó}
ÉÏÈı½Ç¾ØÕó(ÉÏÃæµÄÈı½Ç²»Îª0,¶øÏÂÃæµÄÈı½ÇÎªÁãµÄ¾ØÕó) \newline
ÏÂÈı½Ç¾ØÕó(ÏÂÃæµÄÈı½Ç²»Îª0,¶øÉÏÃæµÄÈı½ÇÎªÁãµÄ¾ØÕó)
\begin{note}
  ÓÃ³õµÈ¾ØÕó×ó(ÓÒ)³ËÒ»¸ö¾ØÕóA,¾ÍÏàµ±ÓÚ¶ÔA½øĞĞÁËÒ»´ÎÏàÓ¦µÄ³õµÈĞĞ(ÁĞ)±ä»»
\end{note}
\subsubsection{»ù±¾¾ØÕó}
Ö»ÓĞÒ»¸öÔªËØÎª1,ÆäÓàÔªËØ¾ùÎª0µÄ¾ØÕó \newline
(i,j)ÔªÎª1µÄ»ù±¾¾ØÕó¼ÇÎª$E_{ij}$
ÈÎÒâÒ»¸ö¾ØÕóA¶¼¿ÉÒÔ¼ÇÎª$A=\sum_{i=1}^s {\sum_{j=1}^n {a_{ij}E_{ij}}}$
\newline
ÓÃ$E_{ij}$×ó(ÓÒ)³ËÒ»¸ö¾ØÕóA,Ïàµ±ÓÚ°ÑAµÄµÚjĞĞ°áµ½µÚiĞĞ(µÚi ÁĞ°áµ½µÚj ÁĞ)µÄÎ»ÖÃ,È»ºó³Ë»ıËùµÃ¾ØÕóµÄÆäÓàĞĞ¾ùÎª0 \newline
$$
E_{ij}E_{kl}=
\begin{cases}
  E_{il} & si~ k=j \\
  0 & si k ~\neq j
\end{cases}
$$

\begin{question}
  Ñ­»·ÒÆÎ»¾ØÕó:
  $$
  C=
  \begin{bmatrix}
    \epsilon_n & \epsilon_1 & \epsilon_2 & \epsilon_3 & \dots & \epsilon_{n-2} & \epsilon_{n-1} \\
    \hline
        0      &     1      &     0      &       0    & \dots &      0         &       0        \\
        0      &     0      &     1      &       0    & \dots &      0         &       0        \\
        0      &     0      &     0      &       1    & \dots &      0         &       0        \\
        \vdots &    \vdots  &     \vdots &     \vdots & \ddots&      \vdots    &       \vdots   \\
        0      &     0      &     0      &       0    & \dots &      0         &       1        \\
        1      &     0      &     0      &       0    & \dots &      0         &       0
  \end{bmatrix}
  $$
  (1)ÓÃC×ó³ËA,Ïàµ±ÓÚ°ÑA µÄĞĞÏòÉÏÒÆÒ»ĞĞ,µÚÒ»ĞĞ»»µ½×îºóÒ»ĞĞ \newline
  ÓÃCÓÒ³ËB,Ïàµ±ÓÚ°ÑB µÄÁĞÏòÓÒÒÆÒ»ÁĞ,×îºóÒ»ÁĞ»»µ½µÚÒ»ÁĞ \newline
  (2)$\sum_{l=0}^{n-1} C^l=J$,ÆäÖĞJ ÎªÔªËØÈ«Îª1 µÄn ¼¶¾ØÕó
\end{question}
\begin{proof}[Demontration(2)]
  $\newline C=(\epsilon_n,\epsilon_1 , \epsilon_2 ,\epsilon_3 , \dots , \epsilon_{n-2}, \epsilon_{n-1} ) \\
    C^2=( \epsilon_{n-1},\epsilon_n,\epsilon_1 , \epsilon_2 ,\epsilon_3 , \dots , \epsilon_{n-2}  ) \\
    C^3=(\epsilon_{n-2}, \epsilon_{n-1},\epsilon_n,\epsilon_1 , \epsilon_2 ,\epsilon_3 , \dots , \epsilon_{n-3}  ) \\
    until \\
    C^{n-1}=(\epsilon_2 ,\epsilon_3 , \dots , \epsilon_n,\epsilon_1 ) \\
    \sum_{l=0}^{n-1} C^l=
    (\epsilon_n,\epsilon_1 , \epsilon_2 , \dots , \epsilon_{n-2}, \epsilon_{n-1} ) +
    ( \epsilon_{n-1},\epsilon_n,\epsilon_1 , \dots , \epsilon_{n-2}  ) +
    (\epsilon_{n-2}, \epsilon_{n-1},\epsilon_n,\epsilon_1 , \dots , \epsilon_{n-3}  ) +
    (\epsilon_2 ,\epsilon_3 , \dots , \epsilon_n,\epsilon_1 ) \\
    =(\epsilon_1+\epsilon_n+\epsilon_{n-1}+\dots+\epsilon_1,\epsilon_2+\epsilon_1+\epsilon_n+\dots+\epsilon_3,\dots,\epsilon_n+\epsilon_{n-1}+\dots+\epsilon_1)\\
    =
    \begin{bmatrix}
      1 & 1 & 1 & \cdots & 1 \\
      1 & 1 & 1 & \cdots & 1 \\
      \vdots &\vdots &\vdots &\vdots &\vdots \\
      1 & 1 & 1 & \cdots & 1 \\
    \end{bmatrix}
    =J$
\end{proof}
\subsection{Rang ÖÈ}
$$rang(AB)\leqslant rang(A)$$
$$rang(A+B)\leqslant rang(A)+rang(B)$$
$$  \mathrm{si} ~k \neq 0, rang(kA)=rang(A)$$


%############################################################## Algebre 2 µÚ¶şÕÂ #########################################################################
\section{D\'etermiants}

\end{document} 