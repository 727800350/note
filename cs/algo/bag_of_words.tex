\chapter{BOW(Bag of Words)}
\href{https://www.douban.com/note/310140053/}{Bag of Words(BOW)模型}

Bag-of-words模型是信息检索领域常用的文档表示方法. 在信息检索中,BOW模型假定对于一个文档,忽略它的单词顺序和语法,句法等要素,将其仅仅看作是若干个词汇的集合,文档中每个单词的出现都是独立的,不依赖于其它单词是否出现.
也就是说,文档中任意一个位置出现的任何单词,都不受该文档语意影响而独立选择的.
例如有如下两个文档:
\begin{enumerate}
	\item Bob likes to play basketball, Jim likes too.
	\item Bob also likes to play football games.
\end{enumerate}
基于这两个文本文档,构造一个词典:

Dictionary = \{1:"Bob", 2:"like", 3:"to", 4:"play", 5:"basketball", 6:"also", 7:"football", 8:"games", 9:"Jim", 10:"too"\}
 
这个词典一共包含10个不同的单词,利用词典的索引号,上面两个文档每一个都可以用一个10维向量表示(用整数数字0~n(n为正整数)表示某个单词在文档中出现的次数):
 
\begin{enumerate}
	\item $[1, 2, 1, 1, 1, 0, 0, 0, 1, 1]$
	\item $[1, 1, 1, 1 ,0, 1, 1, 1, 0, 0]$
\end{enumerate}
 
向量中每个元素表示词典中相关元素在文档中出现的次数.不过,在构造文档向量的过程中可以看到,我们并没有表达单词在原来句子中出现的次序(这是本Bag-of-words模型的缺点之一,不过瑕不掩瑜甚至在此处无关紧要).

\section{为什么要用BOW模型描述图像}
SIFT特征虽然也能描述一幅图像,但是每个SIFT矢量都是$128$维的,而且一幅图像通常都包含成百上千个SIFT矢量,在进行相似度计算时,这个计算量是非常大的,
通行的做法是用聚类算法对这些矢量数据进行聚类,然后用聚类中的一个簇代表BOW中的一个视觉词,将同一幅图像的SIFT矢量映射到视觉词序列生成码本,这样每一幅图像只用一个码本矢量来描述,这样计算相似度时效率就大大提高了.

构建BOW码本步骤:
\begin{enumerate}
\item 假设训练集有M幅图像,对训练图象集进行预处理.包括图像增强,分割,图像统一格式,统一规格等等.
\item 提取SIFT特征.对每一幅图像提取SIFT特征(每一幅图像提取多少个SIFT特征不定).每一个SIFT特征用一个128维的描述子矢量表示,假设M幅图像共提取出N个SIFT特征.
	当然,在提取sift特征的时候,可以将图像打成很多小的patch,然后对每个patch提取SIFT特征.
\item 用K-means对2中提取的N个SIFT特征进行聚类,K-Means算法是一种基于样本间相似性度量的间接聚类方法,此算法以K为参数,把N个对象分为K个簇,以使簇内具有较高的相似度,而簇间相似度较低.
	聚类中心有k个(在BOW模型中聚类中心我们称它们为视觉词),码本的长度也就为k,计算每一幅图像的每一个SIFT特征到这k个视觉词的距离,并将其映射到距离最近的视觉词中(即将该视觉词的对应词频+1).
	完成这一步后,每一幅图像就变成了一个与视觉词序列相对应的词频矢量.
	设视觉词序列为{眼睛 鼻子 嘴}(k=3),则训练集中的图像变为: 第一幅图像:$[1 0 0]$, 第二幅图像:$[5 3 4], \ldots$.
\item 构造码本.码本矢量归一化因为每一幅图像的SIFT特征个数不定,所以需要归一化.如上述例子,归一化后为$[1 0 0], 1/12*[5 3 4]$.
	测试图像也需经过预处理,提取SIFT特征,将这些特征映射到为码本矢量,码本矢量归一化,最后计算其与训练码本的距离,对应最近距离的训练图像认为与测试图像匹配.
\end{enumerate}

