% !Mode:: "TeX:UTF-8"
\documentclass{article}
\input{../../public/package}
\input{../../public/article}
\begin{document}
\title{Traitement du signal}
\maketitle
\tableofcontents
\newpage

\section{Introduction}
模拟信号: 连续时间连续幅度变化

数字信号处理系统的三种方式: 软件实现; 硬件实现; 软硬件结合(数字信号处理器Digital Signal Processor,DSP)

数字信号处理系统由耗电的有源器件(晶体管)构成; 而模拟处理系统使用电阻, 电容, 电感等无源器件, 所以数字处理系统的功耗比较大.

音乐信号的处理:  
如使用压缩器和扩张器来压缩或扩张音乐信号的幅度范围;
使用均衡器和滤波器改变音乐信号的频率分布

\section{\'Echantillonnage}
采样定理,又称香农采样定理,奈奎斯特采样定理,是信息论,特别是通讯与信号处理学科中的一个重要基本结论

如果信号是带限的,并且采样频率大于信号带宽的2倍,那么,原来的连续信号可以从采样样本中完全重建出来.

\textbf{奈奎斯特频率(Nyquist频率)}是离散信号系统采样频率的一半.

只要离散系统的奈奎斯特频率高于被采样信号的最高频率或带宽,就可以避免混叠现象.

如果不能满足上述采样条件,采样后信号的频率就会重叠,即高于采样频率一半的频率成分将被重建成低于采样频率一半的信号.这种频谱的重叠导致的失真称为混叠,而重建出来的信号称为原信号的混叠替身,因为这两个信号有同样的样本值.

Le th\'eor\`eme d'\'echantillonnage \'enonce que l'\'echantillonnage d'un signal, c'est-\`a-dire sa repr\'esentation sous une forme discr\`ete, par une liste de valeurs pr\'elev\'ees r\'eguli\`erement dans ce signal, exige une fr\'equence d'\'echantillonnage sup\'erieure au double de l'\'ecart entre les fr\'equences minimale et maximale qu'il contient.

Dans le cas le plus courant, la fr\'equence minimale du signal est petite par rapport \`a sa fr\'equence maximale et le th\'eor\`eme affirme plus simplement :

La repr\'esentation discr\`ete d'un signal par des \'echantillons r\'eguli\`erement espac\'es exige une fr\'equence d'\'echantillonnage sup\'erieure au double de la fr\'equence maximale pr\'esente dans ce signal.

En g\'en\'eral, on \'echantillonne dans l'intervalle compris entre 0 et la fr\'equence de Nyquist, c'est-\`a-dire la moiti\'e de la fr\'equence d'\'echantillonnage.

\section{Ergodique 遍历}
L'hypoth\`ese ergodique, ou hypoth\`ese d'ergodicit\'e, est une hypoth\`ese fondamentale de la physique statistique. Elle fut formul\'ee initialement par Ludwig Boltzmann

Elle s'appliquait alors aux syst\`emes compos\'es d'un tr\`es grand nombre de particules, et affirmait qu'\`a l'\'equilibre, la valeur moyenne d'une grandeur calcul\'ee de mani\`ere statistique est \'egale \`a la moyenne d'un tr\`es grand nombre de mesures prises dans le temps.\\
La premi\`ere valeur est celle que permet de calculer la physique statistique, la seconde est proche de ce qu'on peut exp\'erimentalement mesurer.\\
L'hypoth\`ese ergodique est donc fondamentale pour un bon rapprochement entre la th\'eorie et l'exp\'erience.

L'hypoth\`ese d'ergodicit\'e intervient \'egalement en \textbf{traitement du signal}, o\`u elle consiste \`a admettre que \textbf{l'\'evolution d'un signal al\'eatoire au cours du temps apporte la m\^eme information qu'un ensemble de r\'ealisations}.

Elle est importante dans l'\'etude des chaines de Markov, les processus stationnaires et pour l'apprentissage num\'erique.

\textbf{Approche intuitive de l'hypoth\`ese ergodique}\\
D'une facon intuitive, reprendre l'exemple d'un gaz, les milliards de particules qui le constituent peuvent \^etre consid\'er\'ees comme des copies les unes des autres ayant toutes le m\^eme comportement al\'eatoire. 
Elles prennent chacune des valeurs al\'eatoires, probablement diff\'erentes, de position et de vitesse \`a un instant donn\'ee. \\
La vitesse moyenne des particules peut se calculer en \textbf{sommant les vitesses de toutes les particules \`a un instant donn\'e}. \\
Cependant, on peut calculer \'egalement une moyenne en \textbf{consid\'erant une seule particule} mais en mesurant ses vitesses \textbf{\`a diff\'erents instants}.\\
L'hypoth\`ese d'ergodicit\'e revient \`a dire que \textbf{les deux m\'ethodes sont \'equivalentes}.

On peut \'egalement penser \`a une for\^et d'une seule esp\`ece et s'int\'eresser \`a la croissance d'un arbre en fonction du temps : l'hypoth\`ese ergodique revient \`a consid\'erer qu'il est similaire d'observer la for\^et \`a un instant donn\'e qu'un arbre tout au long de sa vie pour en conna\^itre l'\'evolution (par exemple relever le diam\`etre du tronc en fonction du temps ou mesurer tous les diam\`etres de la for\^et et le reporter en fonction de l'age de l'arbre).

\bigskip
Un \textbf{processus ergodique} est un processus stochastique pour lequel les statistiques peuvent \^etre approch\'ees par l'\'etude d'une seule r\'ealisation suffisamment longue.

\bigskip
\textbf{Lien avec la stationnarit\'e}\\
Un signal peut \^etre:\\
stationnaire mais non ergodique.\\
ergodique mais non stationnaire; par exemple le signal $Z(x; \omega)=A(\omega)$ constant pour chaque r\'ealisation.

\section{Representation in Terms of Basis Functions}
下面的section的参考资料:
\href{http://www.amazon.com/Continuous-Discrete-Signal-System-Analysis/dp/0030510198}{Continuous and Discrete Signal and System Analysis}

The set of basis functions: $ \phi_{-N}(t), \ldots, \phi_{-2}(t), \phi_{-1}(t), \phi_0(t), \phi_1(t), \phi_2(t), \ldots, \phi_N(t)$, Where $N$ may be infinity in some cases.\\
The linear combination of these as:
\begin{equation}
x(t) = \sum_{n = -N}^N a_n \phi_n(t)
\label{eq.base.combination}
\end{equation}

One property that is desired for a set of basis functions is known as \textbf{finality of coefficients}.\\
It allows one to determine any given coefficient without needing to know any other coefficient. 
Stated another way, more terms can be added to the representation(to obtain greater accuracy, for example) without making any changes in the earlier coefficients.\\
To achive finality of coefficients, it is necessary that the basis functions be \textbf{orthogonal over the time interval} 
for which the representation is to be valid.

The condition for orthogonality of basis functions requires that for all k,
$$
\int_{t_1}^{t_2} \phi_n(t) \phi_k^{*}(t)
=
\begin{cases}
	0 & k \neq n\\
	\lambda_k & k = n
\end{cases}
$$
where $\phi_k^{*}(t)$ is the complex conjugate of $\phi_k(t)$ and $\lambda_k$ is real. For real basis functions this condition becomes:
$$
\int_{t_1}^{t_2} \phi_n(t) \phi_k(t)
=
\begin{cases}
	0 & k \neq n\\
	\lambda_k & k = n
\end{cases}
$$
If $\lambda_k = 1$ for all $k$, the basis functions are said to be \textbf{orthonormal}.

The limits of integration in the last two equations can define either a finite interval or an infinite(semi-infinite) interval, 
depending upon the nature of problem.

In order to demonstrate how the coefficients can be determined, multiply both sides of equation \eqref{eq.base.combination} by $\phi_j^{*}(t)$ , for any $j$, and integrate over the specified interval. This gives
\begin{equation}
\int_{t_1}^{t_2} \phi_j^{*}(t)x(t)dt 
= \int_{t_1}^{t_2} \phi_j^{*}(t) [\sum_{n = -N}^N a_n \phi_n(t)] dt 
= \sum_{n = -N}^N a_n \int_{t_1}^{t_2} \phi_j^{*}(t) \phi_n(t) dt 
\end{equation}

From the orthogonality condition, equation \lasteq may be written as
$$ \int_{t_1}^{t_2} \phi_j^{*}(t) x(t) dt = a_j \lambda $$
Since all the terms on the right side of equation \lasteq will be zero except for $n = j$. Thus, the coefficient $a_j$ may be expressed quite generally as
\begin{equation}
a_j = \frac{1}{\lambda_j} \int_{t_1}^{t_2} \phi_j^*(t) x(t) dt
\end{equation}

When the basis functions are complex, eg., a complex Fourier series representation, it is very likely that the coefficients $a_j$ will be complex too.

The enery or average power of a signal:
\begin{equation}
E 
= \int_{t_1}^{t_2}x^2(t)dt
= \int_{t_1}^{t_2}x(t) \sum_{n = -N}^N a_n \phi_n(t) dt
= \sum_{n = -N}^N a_n \int_{t_1}^{t_2}x(t) \phi_n(t) dt
\end{equation}
Now it is seen that, assuming $x(t)$ is real, the integral in equation \lasteq is $\lambda_n$ times the complex conjugate of $a_n$. Therefore,
\begin{equation}
E
= \sum_{n = -N}^N a_n \lambda_n a_n^* = \sum_{n = -N}^N \lambda_n \norm{a_n}^2
\end{equation}

\subsection{Energy}
Since $\lambda_n$ is the energy in the nth basis function, 
each term of the summation in \lasteq is simply the energy associated with the nth component of the representation. 
Thus, \lasteq states that \textbf{the energy of singal is the sum of the energies of its individual orthogonal components, regardless of what form they may have}. \\
This is one form of a quite general theorm that is usually referred to as \textit{Parseval}'s theorem.

In almost all cases, the value of $N$ in equation \eqref{eq.base.combination} required for an exact representation will be infinity,
but the values of $a_n$ tend to be smaller as $n$ becomes large. 

\subsection{Approximation}
Since it is not possible to use an infinite number of terms in any pratical situation, 
the series must be terminated after some finite number of terms, and the resulting expression is an approximation to $x(t)$. 

Thus the approximation $\hat{x}(t)$ may be expressed as
\begin{equation}
\hat{x}(t) = \sum_{n = -M}^M a_n \phi_n(t)
\end{equation}

The integral squared error:
$$
I = \int_{t_1}^{t_2} \norm{x(t) - \hat{x}(t)}^2 dt
$$
经过一系列的运算, 我们可以证明当$I$ 取最小值时, $\hat{a}_n = a_n$.\\
From this result it may be conclued that the previously defined coefficients $a_n$ are also the best ones from the standpoint of minimizing the approximation error when only a finite number of terms is used.

\section{M\'ethode de Monte-Carlo}
Le terme m\'ethode de Monte-Carlo, d\'esigne toute m\'ethode visant \`a calculer une valeur num\'erique en utilisant des proc\'ed\'es al\'eatoires, c'est-\`a-dire des techniques probabilistes.

Les m\'ethodes de Monte-Carlo sont particuli\`erement utilis\'ees pour calculer des int\'egrales en dimensions plus grandes que 1 (en particulier, pour calculer des surfaces et des volumes). Elles sont \'egalement couramment utilis\'ees en physique des particules, o\`u des simulations probabilistes permettent d'estimer la forme d'un signal ou la sensibilit\'e d'un d\'etecteur. La comparaison des donn\'ees mesur\'ees \`a ces simulations peut permettre de mettre en \'evidence des caract\'eristiques inattendues, par exemple de nouvelles particules.

\textbf{蒙特卡罗方法的基本思想}\\
通常蒙特卡罗方法可以粗略地分成两类:
\begin{itemize}
\item 一类是所求解的问题本身具有\textbf{内在的随机性},借助计算机的运算能力可以直接模拟这种随机的过程.例如在核物理研究中,分析中子在反应堆中的传输过程.中子与原子核作用受到量子力学规律的制约,人们只能知道它们相互作用发生的概率,却无法准确获得中子与原子核作用时的位置以及裂变产生的新中子的行进速率和方向.科学家依据其概率进行随机抽样得到裂变位置,速度和方向,这样模拟大量中子的行为后,经过统计就能获得中子传输的范围,作为反应堆设计的依据.
\item 另一种类型是所求解问题可以\textbf{转化为某种随机分布的特征数},比如随机事件出现的概率,或者随机变量的期望值.通过随机抽样的方法,以随机事件出现的频率估计其概率,或者以抽样的数字特征估算随机变量的数字特征,并将其作为问题的解.这种方法多用于求解复杂的多维积分问题.
\end{itemize}
假设我们要计算一个不规则图形的面积,那么图形的不规则程度和分析性计算(比如,积分)的复杂程度是成正比的.蒙特卡罗方法基于这样的思想:假想你有一袋豆子,把豆子均匀地朝这个图形上撒,然后数这个图形之中有多少颗豆子,这个豆子的数目就是图形的面积.当你的豆子越小,撒的越多的时候,结果就越精确.借助计算机程序可以生成大量均匀分布坐标点,然后统计出图形内的点数,通过它们占总点数的比例和坐标点生成范围的面积就可以求出图形面积.

\subsection{Th\'erie de Monte Carlo}
Nous disposons de l'expression de l'esp\'erance math\'ematique d'une fonction $g$ de variable al\'eatoire $X$:
$$ G = E(g(X))=\int g(x)f_X(x) \, \mbox{d}x $$
o\`u $f_X$ est une fonction de densit\'e sur le support $[a;b]$. Il est fr\'equent de prendre une distribution uniforme sur $[a;b]$:

$$ f_X(x) = \frac{1}{b-a} $$
Ceci peut \^etre \'etendu aux probabilit\'es discr\`etes en sommant grace \`a une mesure $\nu$ discr\`ete, de type Dirac.

L'id\'ee est de \textbf{produire un \'echantillon} $(x_1,x_2,...,x_N)$ de la loi $X$ (donc d'apr\`es la densit\'e $f_X$) sur le support $[a;b]$, et de \textbf{calculer un nouvel estimateur dit de Monte-Carlo}, \`a partir de cet \'echantillon.

La loi des grands nombres sugg\`ere de construire cet estimateur \`a partir de la moyenne empirique :
$$ \tilde{g_N} = \frac{1}{N} \sum_{i=1}^{N} g(x_i), $$
qui se trouve \^etre, par ailleurs, un \textbf{estimateur sans biais de l'esp\'erance}.

Ceci est l'estimateur de Monte-Carlo. Nous voyons bien qu'en rempla\c{c}ant l'\'echantillon par un ensemble de valeurs prises dans le support d'une int\'egrale, et de la fonction \`a int\'egrer, nous pouvons donc construire une approximation de sa valeur, construite statistiquement.

Cette estimation est sans biais, dans le sens o\`u
$$ E(\tilde{g_N})= G = E(g(X)) $$
Il faut aussi quantifier la pr\'ecision de cette estimation, via la variance de $\tilde{g_N}$. Si l'\'echantillon est suppos\'e iid(Ind\'ependant identiquement distribu\'e), cette variance est estim\'ee \`a l'aide de la variance empirique
$$ S^2_{g(X)} = \frac{1}{N} \sum_{i=1}^N (g(x_i) - \tilde{g_N})^2 \simeq \sigma_g^2 $$
avec
$$ \sigma_g^2= E(g^2(X)) - E(g(X))^2 = \int_{\Omega} g^2(x) f_X(x) \,\mbox{d} x - G^2 $$

Par le th\'eor\`eme de la limite centrale, on sait que la variable :
$$ Z := \frac{\tilde{g_N}-G}{\sigma_g / \sqrt{N}} \equiv \mathcal{N} \; \left(0;1\right) $$
qui est centr\'ee et r\'eduite, suit approximativement la loi normale centr\'ee r\'eduite, ou loi de Gauss. Il est alors possible de construire des intervalles de confiance

\section{The implulse function}
delta function

It should be emphasized that the factor multiplying an impulse is really designing the \textit{area} of the impulse and is not just scaling its magnitude.
Thus, $A\delta(t-a)$ is an impulse with an area of $A$ located at $t=0$

The delta function is defined to be a function satisfies the following conditions:
\begin{enumerate}
\item $\delta(t - t_0) = 0 \eqspace t \neq t_0$
\item $\int_{t_1}^{t_2} \delta(t - t_0)dt =1 \eqspace t_1 < t_0 < t_2$
\item $\int_{- \infty}^{+ \infty} f(t) \delta(t - t_0)dt = f(t_0) \eqspace f(t) \text{continuous at }t_0$
\end{enumerate}

\bigskip
Some other properties:\\
Time scaling:
$$ \delta(bt - t_0) = \frac{1}{\norm{b}} \delta(t - \frac{t_0}{b}) $$

Integral of product of delta function:
$$ \int_{t_1}^{t_2} \delta(\lambda - t) \delta(\lambda - t_0)d \lambda = \delta(t - t_0) \eqspace t_1 < t_0 < t_2 $$

\section{Fourier Transform}
Suppose $x(t)$ a periodic function with period $T$
$$ x(t) = \sum_{n = - \infty}^{\infty} \alpha_n e^{jn\omega_0 t} $$

The Fourier transform then becomes:
$$
\begin{aligned}
		X(\omega) & = \mathcal{F}\{\sum_{n = - \infty}^{\infty} \alpha_n e^{jn\omega_0 t}\} \\
				  & =  \sum_{n = - \infty}^{\infty} \alpha_n \mathcal{F}\{e^{jn\omega_0 t}\} \\
				  & =  2\pi \sum_{n = - \infty}^{\infty} \alpha_n \delta(\omega - n \omega_0)
\end{aligned}
$$

The constants $\alpha_n$ can be expressed in terms of the Fourier transform of $x_T(t)$, the waveform over one period, as fllows:
$$
\begin{aligned}
		\alpha_n & = \frac{1}{T} \int_{ - T/2}^{T/2} x(t) e^{-jn\omega_0 t}dt \\
			     & = \frac{1}{T} \int_{ - T/2}^{T/2} x_T(t) e^{-jn\omega_0 t}dt \\
  				   & = \frac{1}{T} X_T(n\omega_0)
\end{aligned}
$$

Therefore, 
$$ X(\omega) = \omega_0 \sum_{n = - \infty}^{\infty} X_T(n\omega_0)\delta(\omega - n \omega_0) $$
$$ x(t) \Leftrightarrow \frac{2\pi}{T} \sum_{n = - \infty}^{\infty} X_T(\frac{2\pi n}{T})\delta(\omega - \frac{2\pi n}{T}) $$

The Fourier transform is thus seen to be a series of impulses at the harmonics of the repetition period with strengths determined by the shape of the waveform in one period.

\subsection{Unit Impulse Train}
\href{http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Dirac\_comb.svg/300px-Dirac\_comb.svg.png}{Figure of Unit Impulse Train}

$$x(t) = \sum_{n = - \infty}^{\infty} \delta(t - nT)$$
写成Fourier Series 的形式:
$$x(t) = \sum_{n = - \infty}^{\infty} \alpha_n e^{jn\omega_0 t} \eqspace \omega_0 = \frac{2\pi}{T}$$

$$
\begin{aligned}
		\alpha_n & = \frac{1}{T} \int_{ - T/2}^{T/2} x(t) e^{-jn\omega_0 t}dt \\
				& = \frac{1}{T} \int_{ - T/2}^{T/2} (\sum_{n = - \infty}^{\infty} \delta(t - nT)) e^{-jn\omega_0 t}dt \\
				& = \sum_{n=-\infty}^{\infty} \frac{1}{T} \int_{ - T/2}^{T/2} \delta(t - nT) e^{-jn\omega_0 t}dt \\
			 	&\text{As nT in [-T/2, T/2], n can only equal to 0}\\
				 &= \frac{1}{T} \int_{-T/2}^{T/2} \delta(t) \times 1 dt \\
				 & = \frac{1}{T}
\end{aligned}
$$

Therefore, $x(t)$ can be written as
$$ x(t) = \frac{1}{T} \sum_{n = - \infty}^{\infty} e^{jn\omega_0 t} $$
Taking the Fourier transform gives:
\begin{equation}
\begin{aligned}
X(\omega)
& = \frac{1}{T} \sum_{n = -\infty}^{\infty} \mathcal{F}\{ e^{jn\omega_0 t} \} \\
& = \frac{2\pi}{T} \sum_{n = -\infty}^{\infty} \delta(\omega - n\omega_0) \\
\sum_{n = - \infty}^{\infty} \delta(t - nT)
& \Leftrightarrow
\frac{2\pi}{T} \sum_{n = -\infty}^{\infty} \delta(\omega - n\omega_0) \\
\end{aligned}
\end{equation}

In terms of frequency $f$, \lasteq can be written as
$$
\sum_{n = - \infty}^{\infty} \delta(t - nT)
\Leftrightarrow
\frac{1}{T} \sum_{n = -\infty}^{\infty} \delta(f - \dfrac{n}{T}) \\
$$

Thus, it is seen that an impulse train in the time domaine has as its Fourier transform an impulse train in the frequency domain.

Unit impulse train 在时域(a)与频域(b)上的对比:
\href{http://i.imgbox.com/GHbA7Fbm.jpg}{The Unit impulse train}
\end{document}
